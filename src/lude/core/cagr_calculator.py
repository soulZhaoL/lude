"""
å¯è½¬å€ºCAGRè®¡ç®—å™¨ - ç²¾ç®€ç‰ˆ

æœ¬æ¨¡å—æä¾›è®¡ç®—å¯è½¬å€ºç»„åˆCAGRçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œæ”¯æŒæ­¢ç›ˆå’Œéæ­¢ç›ˆä¸¤ç§æ¨¡å¼ã€‚
åŸºäºmore_factor_test_origin_code_none_threadhold.pyç²¾ç®€è€Œæ¥ï¼Œåªä¿ç•™æ ¸å¿ƒè®¡ç®—é€»è¾‘ã€‚
"""

import os
import sys
import warnings

import pandas as pd
import numpy as np
from numpy import nan
from typing import Dict
from lude.utils.logger import optimization_logger as logger

from lude.utils.cagr_utils import calculate_cagr_manually
from lude.config.paths import DATA_DIR


def calculate_overfitting_severity(warning_messages):
    """
    æ ¹æ®è¿‡æ‹Ÿåˆè­¦å‘Šä¿¡æ¯è®¡ç®—ä¸¥é‡ç¨‹åº¦
    
    å‚æ•°:
        warning_messages: è¿‡æ‹Ÿåˆè­¦å‘Šä¿¡æ¯åˆ—è¡¨
    
    è¿”å›:
        float: ä¸¥é‡ç¨‹åº¦ç³»æ•° (1.0-3.0)
    """
    if not warning_messages:
        return 1.0
    
    severity = 1.0
    for msg in warning_messages:
        if "å˜å¼‚ç³»æ•°" in msg:
            # æå–å˜å¼‚ç³»æ•°æ•°å€¼
            try:
                import re
                cv_match = re.search(r'å˜å¼‚ç³»æ•°\s+([\d.]+)', msg)
                if cv_match:
                    cv_value = float(cv_match.group(1))
                    # å˜å¼‚ç³»æ•°è¶Šå¤§ï¼Œä¸¥é‡ç¨‹åº¦è¶Šé«˜
                    if cv_value > 2.0:
                        severity = min(severity + 1.0, 3.0)
                    elif cv_value > 1.5:
                        severity = min(severity + 0.5, 3.0)
            except:
                severity = min(severity + 0.3, 3.0)
        
        elif "äº¤æ˜“å¤©æ•°ä¸è¶³" in msg:
            severity = min(severity + 0.8, 3.0)
        elif "è¡¨ç°ä¸ç¨³å®š" in msg:
            severity = min(severity + 0.6, 3.0)
        else:
            severity = min(severity + 0.2, 3.0)
    
    return severity

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# åŸºç¡€å¸¸é‡è®¾ç½®
SP = 0.06  # ç›˜ä¸­æ­¢ç›ˆæ¡ä»¶ï¼Œ6%æ­¢ç›ˆ
C_RATE = 2 / 1000  # ä¹°å–ä¸€æ¬¡èŠ±è´¹çš„æ€»ä½£é‡‘å’Œæ»‘ç‚¹ï¼ˆåŒè¾¹ï¼‰
threshold_num = None  # è½®åŠ¨é˜ˆå€¼
YEARLY_FACTOR = 245  # äº¤æ˜“æ—¥æ ‡å‡†å¹´åŒ–å› å­
RISK_FREE = 0.0  # æ— é£é™©åˆ©ç‡


def calculate_risk_metrics(returns: pd.Series, cagr: float) -> Dict[str, float]:
    """
    è®¡ç®—é£é™©æŒ‡æ ‡
    
    å‚æ•°:
        returns: æ—¥æ”¶ç›Šç‡åºåˆ—
        cagr: å¹´åŒ–æ”¶ç›Šç‡
    
    è¿”å›:
        Dict: é£é™©æŒ‡æ ‡å­—å…¸
    """
    try:
        # å°è¯•ä½¿ç”¨quantstatsåº“è®¡ç®—æŒ‡æ ‡
        import quantstats as qs
        
        # è®¡ç®—é£é™©æŒ‡æ ‡
        max_drawdown = abs(qs.stats.max_drawdown(returns))
        sharpe_ratio = qs.stats.sharpe(returns, rf=RISK_FREE, periods=YEARLY_FACTOR)
        sortino_ratio = qs.stats.sortino(returns, rf=RISK_FREE, periods=YEARLY_FACTOR)
        calmar_ratio = cagr / max_drawdown if max_drawdown > 0 else float('inf')
        
    except (ImportError, Exception):
        # ä½¿ç”¨æ ‡å‡†æ–¹æ³•è®¡ç®—é£é™©æŒ‡æ ‡
        
        # è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡
        cum_returns = (1 + returns).cumprod() - 1
        
        # è®¡ç®—æœ€å¤§å›æ’¤
        running_max = cum_returns.cummax()
        drawdown = (cum_returns - running_max) / (1 + running_max)
        max_drawdown = abs(drawdown.min())
        
        # è®¡ç®—å¹´åŒ–æ ‡å‡†å·®
        annual_std = returns.std() * np.sqrt(YEARLY_FACTOR)
        
        # è®¡ç®—å¤æ™®æ¯”ç‡
        sharpe_ratio = (cagr - RISK_FREE) / annual_std if annual_std > 0 else 0
        
        # è®¡ç®—ç´¢æè¯ºæ¯”ç‡
        downside_returns = returns[returns < 0]
        if len(downside_returns) > 0:
            downside_std = downside_returns.std() * np.sqrt(YEARLY_FACTOR)
            sortino_ratio = (cagr - RISK_FREE) / downside_std if downside_std > 0 else 0
        else:
            sortino_ratio = float('inf')
        
        # è®¡ç®—å¡ç›æ¯”ç‡
        calmar_ratio = cagr / max_drawdown if max_drawdown > 0 else float('inf')
    
    # è¿”å›æ‰€æœ‰é£é™©æŒ‡æ ‡
    return {
        'max_drawdown': max_drawdown,
        'sharpe_ratio': sharpe_ratio,
        'sortino_ratio': sortino_ratio,
        'calmar_ratio': calmar_ratio
    }


def calculate_bonds_cagr(df, start_date, end_date, hold_num, min_price, max_price,
                         rank_factors, threshold_num=None, filter_conditions=None,
                         check_overfitting=True, verbose_overfitting=False, return_details=False):
    """
    è®¡ç®—å¯è½¬å€ºç»„åˆçš„CAGR
    
    å‚æ•°ï¼š
        df: å¯è½¬å€ºæ•°æ®DataFrame
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼'YYYYMMDD'
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼'YYYYMMDD'
        hold_num: æŒæœ‰æ•°é‡
        min_price: æœ€ä½ä»·æ ¼ç­›é€‰
        max_price: æœ€é«˜ä»·æ ¼ç­›é€‰
        rank_factors: æ’åºå› å­ï¼Œæ ¼å¼ä¸º[{'name': 'å› å­å', 'weight': æƒé‡, 'ascending': æ’åºæ–¹å‘}, ...]
        threshold_num: è½®åŠ¨é˜ˆå€¼ï¼Œé»˜è®¤ä¸ºNone
        filter_conditions: æ’é™¤å› å­ç»„åˆï¼Œæ ¼å¼ä¸º[{'factor': 'å› å­å', 'operator': '>=', 'value': é˜ˆå€¼}, ...]
        check_overfitting: æ˜¯å¦è¿›è¡Œè¿‡æ‹Ÿåˆæ£€æµ‹ï¼Œé»˜è®¤ä¸ºTrue
        verbose_overfitting: æ˜¯å¦æ‰“å°è¿‡æ‹Ÿåˆæ£€æµ‹è¯¦ç»†ä¿¡æ¯ï¼Œé»˜è®¤ä¸ºFalse
        return_details: æ˜¯å¦è¿”å›è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«é£é™©æŒ‡æ ‡ã€é€‰ä¸­å€ºåˆ¸ç­‰ï¼‰ï¼Œé»˜è®¤ä¸ºFalse
    
    è¿”å›ï¼š
        å¦‚æœ return_details=False: è¿”å› CAGR å€¼ï¼ˆfloatï¼‰
        å¦‚æœ return_details=True: è¿”å›è¯¦ç»†ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - cagr: å¹´åŒ–æ”¶ç›Šç‡
            - max_drawdown: æœ€å¤§å›æ’¤ç‡  
            - sharpe_ratio: å¤æ™®æ¯”ç‡
            - sortino_ratio: ç´¢æè¯ºæ¯”ç‡
            - calmar_ratio: å¡ç›æ¯”ç‡
            - daily_selected_bonds: æ¯æ—¥é€‰ä¸­çš„å¯è½¬å€ºDataFrame
            - daily_returns: æ¯æ—¥æ”¶ç›Šç‡DataFrame
            - processed_df: å¤„ç†åçš„æ•°æ®æ¡†
    """
    # logger.info(f"rank_factors:{rank_factors}, filter_conditions:{filter_conditions}")
    # æ•°æ®ç­›é€‰ - æŒ‰æ—¥æœŸèŒƒå›´
    df = df[(df.index.get_level_values('trade_date') >= start_date) &
            (df.index.get_level_values('trade_date') <= end_date)]

    # åˆå§‹åŒ–è¿‡æ»¤å™¨
    df['filter'] = False

    # è®¡ç®—æ”¶ç›˜ä»·ç™¾åˆ†æ¯”æ’å
    df['close_pct'] = df.groupby('trade_date')['close'].rank(pct=True)

    # åŸºç¡€æ’é™¤æ¡ä»¶è®¾ç½®
    df.loc[df.is_call.isin(['å·²å…¬å‘Šå¼ºèµ', 'å…¬å‘Šåˆ°æœŸèµå›', 'å…¬å‘Šå®æ–½å¼ºèµ',
                            'å…¬å‘Šæç¤ºå¼ºèµ', 'å·²æ»¡è¶³å¼ºèµæ¡ä»¶']), 'filter'] = True  # æ’é™¤èµå›çŠ¶æ€
    df.loc[df.list_days <= 3, 'filter'] = True  # æ’é™¤æ–°å€º
    df.loc[df.left_years < 0.5, 'filter'] = True  # æ’é™¤åˆ°æœŸæ—¥å°äº0.5å¹´çš„æ ‡çš„
    df.loc[df.amount < 1000, 'filter'] = True  # æ’é™¤æˆäº¤é¢å°äº1000ä¸‡
    df.loc[df.close > max_price, 'filter'] = True  # æ’é™¤ä»·æ ¼è¿‡é«˜
    df.loc[df.close < min_price, 'filter'] = True  # æ’é™¤ä»·æ ¼è¿‡ä½
    
    # åº”ç”¨æ’é™¤å› å­ç»„åˆè¿‡æ»¤æ¡ä»¶
    # if filter_conditions is None:
    #     # å¦‚æœæ²¡æœ‰æä¾›æ’é™¤å› å­ï¼Œä½¿ç”¨é»˜è®¤æ’é™¤å› å­
    #     filter_conditions = [
    #         {'factor': 'amount', 'operator': '<', 'value': 1000},  # é»˜è®¤æ’é™¤æˆäº¤é¢å°äº1000ä¸‡
    #         {'factor': 'close', 'operator': '>', 'value': max_price},  # é»˜è®¤æ’é™¤ä»·æ ¼è¿‡é«˜
    #         {'factor': 'close', 'operator': '<', 'value': min_price},  # é»˜è®¤æ’é™¤ä»·æ ¼è¿‡ä½
    #     ]
    
    # åº”ç”¨åŠ¨æ€æ’é™¤å› å­æ¡ä»¶
    if filter_conditions:
        for condition in filter_conditions:
            factor_name = condition['factor']
            operator = condition['operator']
            threshold = condition['value']
            
            if factor_name in df.columns:
                if operator == '>=':
                    df.loc[df[factor_name] >= threshold, 'filter'] = True
                elif operator == '>':
                    df.loc[df[factor_name] > threshold, 'filter'] = True
                elif operator == '<=':
                    df.loc[df[factor_name] <= threshold, 'filter'] = True
                elif operator == '<':
                    df.loc[df[factor_name] < threshold, 'filter'] = True
                elif operator == '==':
                    df.loc[df[factor_name] == threshold, 'filter'] = True
                elif operator == '!=':
                    df.loc[df[factor_name] != threshold, 'filter'] = True
                # print(f'åº”ç”¨æ’é™¤æ¡ä»¶: {factor_name} {operator} {threshold}')
            else:
                logger.warning(f'è­¦å‘Š: æœªæ‰¾åˆ°æ’é™¤å› å­ã€{factor_name}ã€‘, è·³è¿‡æ­¤æ¡ä»¶')

    # è®¡ç®—å¤šå› å­å¾—åˆ†å’Œæ’å
    trade_date_group = df[df['filter'] == False].groupby('trade_date')

    # åº”ç”¨æ¯ä¸ªå› å­å¹¶è®¡ç®—å¾—åˆ†
    for factor in rank_factors:
        if factor['name'] in df.columns:
            df[f'{factor["name"]}_score'] = trade_date_group[factor["name"]].rank(
                ascending=factor['ascending']) * factor['weight']
        else:
            logger.warning(f'æœªæ‰¾åˆ°å› å­ã€{factor["name"]}ã€‘, è·³è¿‡')

    # è®¡ç®—æ€»å¾—åˆ†å’Œæ’å
    df['score'] = df[df.filter(like='score').columns].sum(axis=1, min_count=1)
    df['rank'] = df.groupby('trade_date')['score'].rank('first', ascending=False)

    # é˜ˆå€¼è½®åŠ¨
    if threshold_num:
        df.rename(columns={'rank': 'ori_rank'}, inplace=True)  # è®°å½•åŸæ’å
        df['rank'] = nan  # åˆå§‹åŒ–æ’å
        df['mod_rank'] = nan  # åˆå§‹åŒ–ä¿®æ­£æ’å
        RANK_INDEX = df.columns.get_loc('rank')  # æ’åä¸‹æ ‡å€¼
        ORI_RANK_INDEX = df.columns.get_loc('ori_rank')  # åŸå§‹æ’åä¸‹æ ‡å€¼
        df.iloc[df.index.get_level_values(1) == df.index.get_level_values(1)[0], RANK_INDEX] = df.iloc[
            df.index.get_level_values(1) == df.index.get_level_values(1)[0], ORI_RANK_INDEX]  # é¦–æ—¥æ’åç­‰äºåŸæ’å

        trade_date_list = df.index.get_level_values('trade_date').unique()  # äº¤æ˜“æ—¥åˆ—è¡¨

        # éå†æ¯ä¸ªäº¤æ˜“æ—¥å¯¹æ’åè¿›è¡Œå¤„ç†
        for trade_date, _df in df.groupby('trade_date'):
            # è·³è¿‡é¦–æ—¥
            if trade_date == df.index.get_level_values(1)[0]:
                continue
            last_trade_date = trade_date_list[trade_date_list.get_loc(trade_date) - 1]  # ä¸Šä¸ªäº¤æ˜“æ—¥æ—¥æœŸ

            # æ„å»ºä¸€ä¸ªåŒ…å«å½“æ—¥åŸå§‹æ’åï¼ˆori_rankï¼‰ã€ä¸Šä¸ªäº¤æ˜“æ—¥æ’åï¼ˆlast_rankï¼‰ã€ä¿®æ­£æ’åï¼ˆmod_rankï¼‰å’Œé‡æ–°æ’åºåçš„æœ€ç»ˆæ’åï¼ˆrankï¼‰çš„_ranks_df
            _ranks_df = df.loc[df.index.get_level_values('trade_date') == trade_date, ['ori_rank']] \
                .merge(df.loc[df.index.get_level_values('trade_date') == last_trade_date, 'rank'], how='left',
                       on='code') \
                .rename(columns={'rank': 'last_rank'})

            # è‹¥ä¸Šä¸€äº¤æ˜“æ—¥æ’ålast_rank <= hold_numï¼Œä»Šæ—¥mod_rank = ori_rank - threshold_numï¼Œå¦åˆ™ä»Šæ—¥mod_rank = ori_rank
            _ranks_df['mod_rank'] = (_ranks_df['ori_rank'] - threshold_num).where(_ranks_df['last_rank'] <= hold_num,
                                                                                  _ranks_df['ori_rank'])
            # æ ¹æ®mod_rank é‡æ–°æ’åºå‡ºä»Šæ—¥rank
            _ranks_df['rank'] = _ranks_df['mod_rank'].rank(method='first')

            # å°†ä»Šæ—¥æœ€ç»ˆæ’årankå†™å…¥åŸdf
            df.loc[df.index.get_level_values('trade_date') == trade_date, ['mod_rank', 'rank']] = _ranks_df[
                ['mod_rank', 'rank']].values

    # æ·»åŠ æ—¥å†…æ­¢ç›ˆé€»è¾‘
    code_group = df.groupby('code')

    # è®¡ç®—æ¬¡æ—¥ä»·æ ¼å’Œé»˜è®¤æ”¶ç›Šç‡
    df['aft_open'] = code_group.open.shift(-1)  # è®¡ç®—æ¬¡æ—¥å¼€ç›˜ä»·
    df['aft_close'] = code_group.close.shift(-1)  # è®¡ç®—æ¬¡æ—¥æ”¶ç›˜ä»·
    df['aft_high'] = code_group.high.shift(-1)  # è®¡ç®—æ¬¡æ—¥æœ€é«˜ä»·
    df['time_return'] = code_group.pct_chg.shift(-1)  # å…ˆè®¡ç®—ä¸æ­¢ç›ˆæƒ…å†µçš„æ”¶ç›Šç‡
    df['SFZY'] = 'æœªæ»¡è¶³æ­¢ç›ˆ'  # å…ˆè®°å½•é»˜è®¤æƒ…å†µ

    # æ ¹æ®å‚æ•°æ§åˆ¶æ˜¯å¦åº”ç”¨æ­¢ç›ˆé€»è¾‘
    if SP:
        # åº”ç”¨æ­¢ç›ˆé€»è¾‘
        # è¦ç¡®ä¿æ‰§è¡Œé¡ºåºçš„æ­£ç¡®æ€§ï¼šå…ˆå¤„ç†æœ€é«˜ä»·ï¼Œåå¤„ç†å¼€ç›˜ä»·

        # å¦‚æœæ¬¡æ—¥æœ€é«˜ä»·è¾¾åˆ°æ­¢ç›ˆæ¡ä»¶ï¼Œåˆ™æŒ‰æ­¢ç›ˆä»·è®¡ç®—æ”¶ç›Š
        df.loc[df['aft_high'] >= df['close'] * (1 + SP), 'time_return'] = SP
        df.loc[df['aft_high'] >= df['close'] * (1 + SP), 'SFZY'] = 'æ»¡è¶³æ­¢ç›ˆ'

        # å¯¹äºå¼€ç›˜ä»·å·²æ»¡è¶³æ­¢ç›ˆæ¡ä»¶çš„è®°å½•ï¼Œä½¿ç”¨å®é™…å¼€ç›˜ä»·è®¡ç®—æ”¶ç›Š
        # è¿™ä¸€æ­¥ä¼šè¦†ç›–éƒ¨åˆ†æœ€é«˜ä»·å·²è®¾ç½®çš„æ”¶ç›Šç‡
        df.loc[df['aft_open'] >= df['close'] * (1 + SP), 'time_return'] = (df['aft_open'] - df['close']) / df['close']

    # æ ‡è®°é€‰ä¸­çš„å¯è½¬å€ºï¼ˆæ’åå‰Nçš„ï¼‰
    df.loc[(df['rank'] <= hold_num), 'signal'] = 1

    # åˆ›å»ºæ¯æ—¥é€‰ä¸­çš„å¯è½¬å€ºè®°å½•
    daily_selected_bonds = df[df['signal'] == 1].copy()
    daily_selected_bonds = daily_selected_bonds.reset_index()

    # åˆ é™¤æ²¡æœ‰æ ‡è®°çš„è¡Œå¹¶æŒ‰æ—¥æœŸæ’åº
    df.dropna(subset=['signal'], inplace=True)

    # æ£€æŸ¥æ˜¯å¦æœ‰ç¬¦åˆæ¡ä»¶çš„å€ºåˆ¸
    if df.empty:
        logger.warning("æ’é™¤æ¡ä»¶è¿‡ä¸¥ï¼Œæ— ç¬¦åˆæ¡ä»¶çš„å€ºåˆ¸æ•°æ®ï¼ŒæŠ›å‡ºå¼‚å¸¸ä»¥è·³è¿‡è¯¥è¯•éªŒ")
        raise ValueError("æ’é™¤æ¡ä»¶è¿‡ä¸¥ï¼Œæ— ç¬¦åˆæ¡ä»¶çš„å€ºåˆ¸æ•°æ®")
    
    df.sort_values(by='trade_date', inplace=True)

    # è®¡ç®—ç»„åˆå›æŠ¥
    res = pd.DataFrame()

    # æŒ‰ç­‰æƒè®¡ç®—ç»„åˆå›æŠ¥
    time_return_series = df.groupby('trade_date')['time_return'].mean()

    # æ£€æŸ¥æ—¶é—´å›æŠ¥åºåˆ—æ˜¯å¦ä¸ºç©º
    if time_return_series.empty:
        logger.warning(f"æ—¶é—´å›æŠ¥åºåˆ—ä¸ºç©ºï¼Œè¿”å›CAGRä¸º0")
        if return_details:
            return {
                'cagr': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'sortino_ratio': 0.0, 'calmar_ratio': 0.0,
                'daily_selected_bonds': daily_selected_bonds, 'daily_returns': pd.DataFrame(), 'processed_df': df
            }
        return 0.0

    res['time_return'] = time_return_series

    # è®¡ç®—æ‰‹ç»­è´¹
    pos_df = df['signal'].unstack('code')
    pos_df.fillna(0, inplace=True)

    # æ£€æŸ¥pos_dfæ˜¯å¦ä¸ºç©º
    if pos_df.empty:
        logger.warning(f"æŒä»“æ•°æ®ä¸ºç©ºï¼Œè¿”å›CAGRä¸º0")
        if return_details:
            return {
                'cagr': 0.0, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'sortino_ratio': 0.0, 'calmar_ratio': 0.0,
                'daily_selected_bonds': daily_selected_bonds, 'daily_returns': res, 'processed_df': df
            }
        return 0.0

    cost_series = pos_df.diff().abs().sum(axis=1) * C_RATE / (pos_df.shift().sum(axis=1) + pos_df.sum(axis=1))
    res['cost'] = cost_series

    # å®‰å…¨åœ°ä¿®æ­£é¦–è¡Œæ‰‹ç»­è´¹ - ç¡®ä¿resæœ‰æ•°æ®ä¸”æœ‰coståˆ—
    if len(res) > 0 and 'cost' in res.columns:
        res.iloc[0, res.columns.get_loc('cost')] = 0.5 * C_RATE  # ä¿®æ­£é¦–è¡Œæ‰‹ç»­è´¹

    # æ‰£é™¤æ‰‹ç»­è´¹åŠä½£é‡‘åçš„å›æŠ¥
    res['daily_return'] = (res['time_return'] + 1) * (1 - res['cost']) - 1

    # ç´¯è®¡æ—¥æ”¶ç›Šç‡
    # res['cumulative_return'] = (1 + res['daily_return']).cumprod() - 1

    # ä½¿ç”¨æ‰‹åŠ¨è®¡ç®—æ³•è®¡ç®—CAGR
    cagr = calculate_cagr_manually(res['daily_return'], start_date, end_date)
    
    # ğŸ¯ æ—©æœŸCAGRè´¨é‡æ£€æŸ¥ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
    if cagr <= 0.0:
        penalty_score = cagr - 0.1  # è´Ÿæ”¶ç›Šé¢å¤–æƒ©ç½š
        logger.warning(f"CAGRä¸ºè´Ÿ({cagr:.6f})ï¼Œè¿”å›æƒ©ç½šåˆ†æ•°: {penalty_score:.6f}, æ‰“åˆ†å› å­: {rank_factors}, æ’é™¤å› å­: {filter_conditions}")
        if return_details:
            return {
                'cagr': penalty_score, 'max_drawdown': 0.0, 'sharpe_ratio': 0.0, 'sortino_ratio': 0.0, 'calmar_ratio': 0.0,
                'daily_selected_bonds': daily_selected_bonds, 'daily_returns': res, 'processed_df': df
            }
        return penalty_score
    
    # è¿‡æ‹Ÿåˆæ£€æµ‹
    final_cagr = cagr  # ä¿å­˜æœ€ç»ˆçš„CAGRå€¼
    
    if check_overfitting:
        from lude.core.overfitting_detector import check_overfitting
        
        try:
            # è¿›è¡Œè¯¦ç»†çš„è¿‡æ‹Ÿåˆæ£€æµ‹
            check_results = check_overfitting(
                df=df,
                daily_selected_bonds=daily_selected_bonds,
                res=res,
                hold_num=hold_num,
                min_trading_days_ratio=0.9,
                verbose=verbose_overfitting
            )
            
            is_overfitted = check_results['overall']['overfitting_detected']
            
            if is_overfitted:
                # è·å–å…·ä½“çš„è¿‡æ‹ŸåˆåŸå› 
                warning_messages = check_results['overall']['warning_messages']
                reason_summary = "; ".join(warning_messages) if warning_messages else "æœªçŸ¥è¿‡æ‹ŸåˆåŸå› "
                
                # ğŸ¯ è®¡ç®—è¿‡æ‹Ÿåˆæƒ©ç½šåˆ†æ•°ï¼Œè®©Optunaå­¦ä¹ 'å'å‚æ•°ç»„åˆ
                overfitting_severity = calculate_overfitting_severity(warning_messages)
                penalty = 0.05 * overfitting_severity  # æ ¹æ®ä¸¥é‡ç¨‹åº¦è°ƒæ•´æƒ©ç½š
                penalty_score = max(cagr - penalty, -0.05)  # ä¿è¯ä¸ä¼šè¿‡åº¦æƒ©ç½š
                
                logger.warning(f"è¿‡æ‹Ÿåˆæƒ©ç½š: CAGR {cagr:.4f} â†’ {penalty_score:.4f}, åŸå› : {reason_summary}, æ‰“åˆ†å› å­: {rank_factors}, æ’é™¤å› å­: {filter_conditions}")
                final_cagr = penalty_score
            else:
                if verbose_overfitting:
                    logger.info(f"æœªæ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼Œè¿”å›æ­£å¸¸CAGR: {cagr:.6f}")

        except ValueError as e:
            # è¿‡æ‹Ÿåˆæ£€æµ‹å¼‚å¸¸ï¼Œé‡æ–°æŠ›å‡ºè®©ä¸Šå±‚å¤„ç†
            raise e
        except Exception as e:
            # å…¶ä»–è¿‡æ‹Ÿåˆæ£€æµ‹é”™è¯¯ï¼Œæ‰“å°è­¦å‘Šä½†ä»ä½¿ç”¨åŸå§‹CAGR
            logger.warning(f"è¿‡æ‹Ÿåˆæ£€æµ‹é‡åˆ°æœªé¢„æœŸé”™è¯¯: {e}")
    else:
        # ä¸è¿›è¡Œè¿‡æ‹Ÿåˆæ£€æµ‹ï¼Œä½¿ç”¨åŸå§‹CAGR
        logger.info(f"ä¸è¿›è¡Œè¿‡æ‹Ÿåˆæ£€æµ‹ï¼Œç›´æ¥è¿”å›CAGR: {cagr:.6f}")
    
    # æ ¹æ®return_detailså‚æ•°å†³å®šè¿”å›æ ¼å¼
    if return_details:
        # è®¡ç®—é£é™©æŒ‡æ ‡
        risk_metrics = calculate_risk_metrics(res['daily_return'], final_cagr)
        
        # è¿”å›è¯¦ç»†ä¿¡æ¯å­—å…¸
        return {
            'cagr': final_cagr,
            'max_drawdown': risk_metrics['max_drawdown'],
            'sharpe_ratio': risk_metrics['sharpe_ratio'],
            'sortino_ratio': risk_metrics['sortino_ratio'],
            'calmar_ratio': risk_metrics['calmar_ratio'],
            'daily_selected_bonds': daily_selected_bonds,
            'daily_returns': res,
            'processed_df': df
        }
    else:
        # è¿”å›ç®€å•çš„CAGRå€¼ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        return final_cagr


if __name__ == '__main__':
    # åŠ è½½æ•°æ®æ–‡ä»¶
    cb_data_path = os.path.join(DATA_DIR, 'cb_data.pq')
    index_data_path = os.path.join(DATA_DIR, 'index.pq')
    
    logger.info(f"åŠ è½½å¯è½¬å€ºæ•°æ®: {cb_data_path}")
    if not os.path.exists(cb_data_path):
        logger.error(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¯è½¬å€ºæ•°æ®æ–‡ä»¶: {cb_data_path}")
        sys.exit(1)
        
    df = pd.read_parquet(cb_data_path)
    
    # å°è¯•åŠ è½½æŒ‡æ•°æ•°æ®
    if os.path.exists(index_data_path):
        logger.info(f"åŠ è½½æŒ‡æ•°æ•°æ®: {index_data_path}")
        index = pd.read_parquet(index_data_path)
    else:
        logger.warning(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°æŒ‡æ•°æ•°æ®æ–‡ä»¶: {index_data_path}")
        index = None

    start_date = '20220729'
    end_date = '20250328'
    hold_num = 5
    min_price = 100
    max_price = 150

    factors = [
        {'name': 'dv_ratio', 'weight': 2, 'ascending': False},
        {'name': 'amount_5', 'weight': 2, 'ascending': True},
        {'name': 'amount_stk', 'weight': 2, 'ascending': True}
    ]

    # è®¡ç®—å¯ç”¨æ­¢ç›ˆæƒ…å†µçš„CAGR
    cagr = calculate_bonds_cagr(
        df, start_date, end_date, hold_num, min_price, max_price, factors, None,
        check_overfitting=True, verbose_overfitting=True
    )

    # æ‰“å°CAGRç»“æœ
    logger.info("å¯ç”¨æ­¢ç›ˆæƒ…å†µçš„CAGR:")
    logger.info(cagr)
