#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¤šé˜¶æ®µä¼˜åŒ–ç­–ç•¥æ¨¡å—
å®ç°å¤šé˜¶æ®µä¼˜åŒ–çš„æ ¸å¿ƒé€»è¾‘

ä¼˜åŒ–å†…å®¹ (2024-07-30):
1. é‡æ„é˜¶æ®µèŒè´£åˆ†ç¦»ï¼š
   - é¢„å¤„ç†é˜¶æ®µï¼šç¡®å®šè¿‡æ»¤æ¡ä»¶ï¼ˆä¸€æ¬¡æ€§ï¼Œä¸åœ¨trialä¸­é‡å¤ç”Ÿæˆï¼‰
   - ç¬¬ä¸€é˜¶æ®µï¼šä¸“æ³¨å› å­ç»„åˆæ¢ç´¢
   - ç¬¬äºŒé˜¶æ®µï¼šä¸“æ³¨æƒé‡å’Œæ’åºæ–¹å‘ä¼˜åŒ–

2. ç®€åŒ–ç›®æ ‡å‡½æ•°ï¼š
   - ç§»é™¤å¤æ‚çš„é—­åŒ…è®¾è®¡
   - ä½¿ç”¨é¢„å…ˆç¡®å®šçš„è¿‡æ»¤æ¡ä»¶ï¼Œé¿å…æ¯ä¸ªtrialé‡æ–°ç”Ÿæˆ
   - æé«˜æ‰§è¡Œæ•ˆç‡å’Œä»£ç å¯è¯»æ€§

3. é…ç½®é©±åŠ¨ä¼˜åŒ–ï¼š
   - è¿‡æ»¤å› å­çš„é€‰æ‹©å®Œå…¨ç”±é…ç½®æ–‡ä»¶filter_factors_optimized_config.yamlé©±åŠ¨
   - max_factorså‚æ•°ä¸¥æ ¼æŒ‰ç…§é…ç½®æ–‡ä»¶ä¸­çš„combination_rules.max_factorsæ‰§è¡Œ
   - ç§»é™¤trialä¸­ä¸å¿…è¦çš„å› å­é€‰æ‹©é€»è¾‘
"""

import itertools
import os
import json
import time
from typing import Dict, Optional

import numpy as np
import optuna

from lude.core.cagr_calculator import calculate_bonds_cagr
from lude.utils.common_utils import RESULTS_DIR  # å¯¼å…¥ç»“æœç›®å½•å¸¸é‡
from lude.utils.logger import optimization_logger as logger
from lude.utils.memory_monitor import check_memory_warning, log_memory_stats

def _validate_filter_conditions(selected_filter_conditions):
    """éªŒè¯æ’é™¤å› å­æ¡ä»¶çš„æœ‰æ•ˆæ€§
    
    Args:
        selected_filter_conditions: é€‰æ‹©çš„æ’é™¤å› å­æ¡ä»¶åˆ—è¡¨
    
    Returns:
        tuple: (is_valid, error_msg)
    """
    if not selected_filter_conditions:
        return True, "æ— æ’é™¤å› å­æ¡ä»¶"
    
    # æ£€æŸ¥é‡å¤å› å­ + æ“ä½œç¬¦ç»„åˆ
    factor_operator_combinations = set()
    factor_conditions = {}  # {factor_name: [conditions]}
    
    for cond in selected_filter_conditions:
        factor_name = cond['factor']
        operator = cond['operator']
        value = cond['value']
        
        # æ£€æŸ¥é‡å¤çš„å› å­+æ“ä½œç¬¦
        factor_op = (factor_name, operator)
        if factor_op in factor_operator_combinations:
            return False, f"å­˜åœ¨é‡å¤çš„å› å­+æ“ä½œç¬¦ç»„åˆ: {factor_name} {operator}"
        factor_operator_combinations.add(factor_op)
        
        # æŒ‰å› å­åˆ†ç»„æ”¶é›†æ¡ä»¶
        if factor_name not in factor_conditions:
            factor_conditions[factor_name] = []
        factor_conditions[factor_name].append({'operator': operator, 'value': value})
    
    # æ£€æŸ¥åŒå› å­çš„èŒƒå›´æ¡ä»¶æ˜¯å¦åˆç†
    for factor_name, conditions in factor_conditions.items():
        if len(conditions) >= 2:
            # æœ‰å¤šä¸ªæ¡ä»¶æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦èƒ½å½¢æˆåˆç†èŒƒå›´
            ge_values = [c['value'] for c in conditions if c['operator'] == '>=']
            le_values = [c['value'] for c in conditions if c['operator'] == '<=']
            
            # å¦‚æœæœ‰>=å’Œ<=æ¡ä»¶ï¼Œæ£€æŸ¥èŒƒå›´åˆç†æ€§
            if ge_values and le_values:
                min_ge = min(ge_values)
                max_le = max(le_values)
                if min_ge > max_le:
                    return False, f"å› å­ {factor_name} çš„èŒƒå›´æ¡ä»¶ä¸åˆç†: >= {min_ge} ä¸” <= {max_le}"
    
    return True, "æ¡ä»¶æœ‰æ•ˆ"


def _prepare_all_filter_conditions(df, enable_filter_opt):
    """é¢„å¤„ç†ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶ï¼ˆç±»ä¼¼æ‰“åˆ†å› å­çš„ç»„åˆç”Ÿæˆï¼‰

    Args:
        df: æ•°æ®æ¡†
        enable_filter_opt: æ˜¯å¦å¯ç”¨è¿‡æ»¤ä¼˜åŒ–

    Returns:
        all_filter_conditions: æ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶åˆ—è¡¨
    """
    if not enable_filter_opt:
        logger.info("è¿‡æ»¤ä¼˜åŒ–æœªå¯ç”¨ï¼Œè·³è¿‡æ’é™¤å› å­æ¡ä»¶ç”Ÿæˆ")
        return None

    try:
        from lude.utils.filter_generator_optimized import OptimizedFilterFactorGenerator

        # ç›´æ¥ä»ä¼˜åŒ–é…ç½®æ–‡ä»¶è·å–æ’é™¤å› å­åˆ—è¡¨
        generator = OptimizedFilterFactorGenerator()
        config_factors = generator.get_available_factors()

        logger.info(f"é…ç½®æ–‡ä»¶ä¸­çš„æ’é™¤å› å­: {config_factors}")

        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶ç»„åˆ
        all_filter_conditions = []
        for factor_name in config_factors:
            # ä½¿ç”¨æ–°ç”Ÿæˆå™¨çš„æ–¹æ³•ç”Ÿæˆå•å› å­æ¡ä»¶
            conditions = generator.generate_single_factor_conditions(factor_name)
            all_filter_conditions.extend(conditions)

        logger.info(f"æˆåŠŸç”Ÿæˆ {len(all_filter_conditions)} ä¸ªå¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶")
        logger.info(
            f"æ¯ä¸ªtrialå°†ä»ä¸­é€‰æ‹©æœ€å¤š {generator.config.get('combination_rules', {}).get('max_factors', 6)} ä¸ªæ¡ä»¶")

        return all_filter_conditions

    except Exception as e:
        logger.error(f"ç”Ÿæˆæ’é™¤å› å­æ¡ä»¶æ—¶å‡ºé”™: {e}")
        return None


def create_optimized_objective_function(df, combinations, args, all_filter_conditions=None, max_filter_factors=6):
    """åˆ›å»ºä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°ï¼ŒåŒæ—¶ä¼˜åŒ–æ‰“åˆ†å› å­å’Œæ’é™¤å› å­

    Args:
        df: æ•°æ®æ¡†
        combinations: æ‰“åˆ†å› å­ç»„åˆåˆ—è¡¨
        args: å‚æ•°
        all_filter_conditions: æ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶åˆ—è¡¨
        max_filter_factors: æœ€å¤§æ’é™¤å› å­æ•°é‡ï¼ˆé¿å…é‡å¤åŠ è½½é…ç½®ï¼‰

    Returns:
        objective: ç›®æ ‡å‡½æ•°
    """
    
    # ========== ğŸ¯ é¢„ç”Ÿæˆæ— æ“ä½œç¬¦å†²çªçš„æ¡ä»¶ç´¢å¼•ç»„åˆ ==========
    filter_index_combinations = []
    if all_filter_conditions and len(all_filter_conditions) > 0:
        max_cond = min(max_filter_factors, len(all_filter_conditions))
        min_cond = max(1, max_cond - 1)  # ç¡®ä¿è‡³å°‘é€‰æ‹©1ä¸ªæ¡ä»¶
        logger.info(f"è¿‡æ»¤å› å­æ¡ä»¶, max_cond: {max_cond}, min_cond: {min_cond}")
        
        # ğŸš¨ å…³é”®è®¾è®¡ï¼šé¢„æ„å»ºæ— æ“ä½œç¬¦å†²çªçš„æœ‰æ•ˆç´¢å¼•ç»„åˆ
        # å…è®¸åŒåå› å­ï¼Œä½†ç¦æ­¢ç›¸åŒæ“ä½œç¬¦é‡å¤ï¼ˆå¦‚ä¸¤ä¸ª"pct_chg >="ï¼‰
        def is_valid_combination(indices):
            """æ£€æŸ¥ç´¢å¼•ç»„åˆæ˜¯å¦æœ‰æ•ˆï¼šç¦æ­¢ç›¸åŒå› å­çš„ç›¸åŒæ“ä½œç¬¦é‡å¤ï¼Œä½†å…è®¸ä¸åŒé˜ˆå€¼"""
            selected_conditions = [all_filter_conditions[i] for i in indices]
            
            # ğŸš¨ å…³é”®ä¿®å¤ï¼šæŒ‰ (factor, operator) åˆ†ç»„ï¼Œä½†å…è®¸ä¸åŒçš„valueå€¼
            # ç»Ÿè®¡æ¯ä¸ª (å› å­,æ“ä½œç¬¦) ç»„åˆçš„å‡ºç°æ¬¡æ•°
            factor_operator_combinations = []
            for condition in selected_conditions:
                combo_key = (condition['factor'], condition['operator'])
                factor_operator_combinations.append(combo_key)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„ (å› å­,æ“ä½œç¬¦) ç»„åˆ
            from collections import Counter
            combo_counts = Counter(factor_operator_combinations)
            
            # å¦‚æœä»»ä½• (å› å­,æ“ä½œç¬¦) ç»„åˆå‡ºç°æ¬¡æ•°>1ï¼Œåˆ™æ— æ•ˆ
            for count in combo_counts.values():
                if count > 1:
                    return False
            return True
        
        # é¢„ç”Ÿæˆæ‰€æœ‰æœ‰æ•ˆçš„ç´¢å¼•ç»„åˆ
        valid_count = 0
        total_count = 0
        for num_conditions in range(min_cond, max_cond + 1):
            for combo_indices in itertools.combinations(range(len(all_filter_conditions)), num_conditions):
                total_count += 1
                if is_valid_combination(combo_indices):
                    filter_index_combinations.append(list(combo_indices))
                    valid_count += 1
        
        logger.info(f"é¢„ç”Ÿæˆ {valid_count} ä¸ªæ— æ“ä½œç¬¦å†²çªçš„æœ‰æ•ˆç´¢å¼•ç»„åˆ (æ€»è®¡{total_count}ä¸ªï¼Œè¿‡æ»¤ç‡{(total_count-valid_count)/total_count*100:.1f}%)")

    def objective(trial):
        # ========== é€‰æ‹©æ‰“åˆ†å› å­ç»„åˆ ==========
        combination_idx = trial.suggest_int("combination_idx", 0, len(combinations) - 1)
        combination = combinations[combination_idx]

        # ä¸ºæ¯ä¸ªæ‰“åˆ†å› å­åˆ†é…æƒé‡å’Œæ’åºæ–¹å‘
        rank_factors = []
        for i, factor in enumerate(combination):
            weight = trial.suggest_int(f"factor{i}_weight", 1, 5)
            ascending = trial.suggest_categorical(f"factor{i}_ascending", [True, False])

            rank_factors.append({"name": factor, "weight": weight, "ascending": ascending})

        # ========== ğŸ¯ é€‰æ‹©æ— æ“ä½œç¬¦å†²çªçš„æ’é™¤å› å­æ¡ä»¶ ==========
        selected_filter_conditions = []
        if filter_index_combinations and all_filter_conditions:
            # ç›´æ¥ä»é¢„æ„å»ºçš„æœ‰æ•ˆç»„åˆä¸­é€‰æ‹©ï¼Œæ— éœ€åå¤„ç†
            combo_idx = trial.suggest_int("filter_combo_idx", 0, len(filter_index_combinations) - 1)
            selected_indices = filter_index_combinations[combo_idx]
            
            # æ ¹æ®ç´¢å¼•è·å–æ¡ä»¶ï¼Œå·²ç¡®ä¿æ— æ“ä½œç¬¦å†²çª
            selected_filter_conditions = [all_filter_conditions[idx] for idx in selected_indices]

            # ğŸ¯ æ–°å¢ï¼šéªŒè¯æ’é™¤å› å­æ¡ä»¶çš„æœ‰æ•ˆæ€§ï¼Œä½¿ç”¨å‰ªææœºåˆ¶å¤„ç†æ— æ•ˆç»„åˆ
            # is_valid, error_msg = _validate_filter_conditions(selected_filter_conditions)
            # if not is_valid:
            #     logger.warning(f"æ£€æµ‹åˆ°æ— æ•ˆçš„æ’é™¤å› å­ç»„åˆ: {error_msg}")
            #     raise optuna.exceptions.TrialPruned()

        # è®¡ç®—CAGR
        try:
            cagr = calculate_bonds_cagr(
                df,
                start_date=args.start_date if args else "20220729",
                end_date=args.end_date if args else "20250328",
                hold_num=args.hold_num if args else 5,
                threshold_num=None,
                min_price=args.price_min if args else 100,
                max_price=args.price_max if args else 150,
                rank_factors=rank_factors,
                filter_conditions=selected_filter_conditions,  # ä½¿ç”¨åŠ¨æ€é€‰æ‹©çš„æ’é™¤å› å­æ¡ä»¶
                check_overfitting=True, verbose_overfitting=False
            )

            # ä¿å­˜åˆ°trial
            trial.set_user_attr("rank_factors", rank_factors)
            trial.set_user_attr("filter_conditions", selected_filter_conditions)

            return cagr
        except ValueError as e:
            # å¤„ç†å‚æ•°ç»„åˆæ— æ•ˆçš„æƒ…å†µï¼ˆè¿‡æ‹Ÿåˆã€æ¡ä»¶è¿‡ä¸¥ç­‰ï¼‰
            if "è¿‡æ‹Ÿåˆ" in str(e) or "æ— ç¬¦åˆæ¡ä»¶" in str(e):
                logger.debug(f"è·³è¿‡æ— æ•ˆå‚æ•°ç»„åˆ: {e}, å½“å‰æ‰“åˆ†å› å­: {rank_factors}, å½“å‰æ’é™¤å› å­: {selected_filter_conditions}")
                logger.debug(f"å½“å‰æ‰“åˆ†å› å­: {rank_factors}")
                logger.debug(f"å½“å‰æ’é™¤å› å­: {selected_filter_conditions}")
                raise optuna.exceptions.TrialPruned()
            else:
                # å…¶ä»–ValueErroré‡æ–°æŠ›å‡º
                raise
        except Exception as e:
            # å¤„ç†å…¶ä»–æœªé¢„æœŸçš„é”™è¯¯
            import traceback
            logger.error(f"è®¡ç®—CAGRæ—¶å‡ºç°æœªé¢„æœŸé”™è¯¯: {e}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            logger.error(f"å½“å‰æ‰“åˆ†å› å­: {rank_factors}")
            logger.error(f"å½“å‰æ’é™¤å› å­: {selected_filter_conditions}")
            raise optuna.exceptions.TrialPruned()

    return objective


def _prepare_first_stage_combinations(factors, num_factors, args, max_combinations):
    """å‡†å¤‡ç¬¬ä¸€é˜¶æ®µçš„å› å­ç»„åˆ

    Args:
        factors: å› å­åˆ—è¡¨
        num_factors: å› å­æ•°é‡
        args: å‚æ•°
        max_combinations: æœ€å¤§ç»„åˆæ•°é‡

    Returns:
        first_stage_combinations: ç¬¬ä¸€é˜¶æ®µå› å­ç»„åˆåˆ—è¡¨
    """
    logger.info(f"å‡†å¤‡ç¬¬ä¸€é˜¶æ®µå› å­ç»„åˆ...")

    # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç»„åˆ
    all_combinations = []
    for combo in itertools.combinations(range(len(factors)), num_factors):
        all_combinations.append(tuple(sorted(combo)))

    # å¦‚æœç»„åˆæ•°é‡è¿‡å¤šï¼Œéšæœºé‡‡æ ·
    if len(all_combinations) > max_combinations:
        np.random.seed(args.seed)
        indices = np.random.choice(len(all_combinations), max_combinations, replace=False)
        all_combinations = [all_combinations[i] for i in indices]

    logger.info(f"ç”Ÿæˆäº† {len(all_combinations)} ä¸ªå› å­ç»„åˆ")

    # å°†ç´¢å¼•ç»„åˆè½¬æ¢ä¸ºå®é™…å› å­ç»„åˆ
    first_stage_combinations = []
    for combo in all_combinations:
        factor_combo = tuple(factors[i] for i in combo)
        first_stage_combinations.append(factor_combo)

    return first_stage_combinations


def _create_study(study_name, args, sampler_type="random"):
    """åˆ›å»ºoptunaç ”ç©¶ - ä½¿ç”¨å¢å¼ºå‹Rediså­˜å‚¨
    
    ğŸš¨ ä¸¥æ ¼åŸåˆ™ï¼šå®Œå…¨ä½¿ç”¨å¢å¼ºå‹å­˜å‚¨ï¼Œä¸å…è®¸é™çº§å¤„ç†
    å¢å¼ºå‹å­˜å‚¨å†…éƒ¨è‡ªå¸¦æ•…éšœè½¬ç§»æœºåˆ¶ï¼Œæ— éœ€é¢å¤–fallback

    Args:
        study_name: ç ”ç©¶åç§°
        args: å‚æ•°
        sampler_type: é‡‡æ ·å™¨ç±»å‹ ("random" æˆ– "tpe")

    Returns:
        study: optunaç ”ç©¶å¯¹è±¡
    """
    from lude.storage.enhanced_redis_storage import create_enhanced_study, load_enhanced_study
    
    # é…ç½®é‡‡æ ·å™¨
    if sampler_type == "random":
        sampler = optuna.samplers.RandomSampler(seed=args.seed)
    else:
        # ğŸš¨ å†…å­˜ä¼˜åŒ–ï¼šTPESampleré…ç½®
        sampler = optuna.samplers.TPESampler(
            seed=args.seed,
            n_startup_trials=10,      # ä»é»˜è®¤10å‡å°‘åˆ°10ï¼ˆå·²ç»æ˜¯æœ€å°ï¼‰
            n_ei_candidates=12,       # ä»é»˜è®¤24å‡å°‘åˆ°12ï¼ˆèŠ‚çœ50%å†…å­˜ï¼‰
            # multivariate=False,       # ç¦ç”¨å¤šå˜é‡é‡‡æ ·ï¼ˆæ˜¾è‘—èŠ‚çœå†…å­˜ï¼‰
            # constant_liar=False,      # ç¦ç”¨å¹¶è¡Œä¼˜åŒ–è°è¨€ç­–ç•¥ï¼ˆèŠ‚çœå†…å­˜ï¼‰
        )

    # å°è¯•åŠ è½½å·²æœ‰çš„ç ”ç©¶
    try:
        study = load_enhanced_study(study_name)
        logger.info(f"âœ… åŠ è½½å·²æœ‰çš„ç ”ç©¶ {study_name}ï¼Œå·²å®Œæˆ {len(study.trials)} æ¬¡è¯•éªŒ")
    except:
        # åˆ›å»ºæ–°çš„ç ”ç©¶ - ä½¿ç”¨å¢å¼ºå‹å­˜å‚¨
        study = create_enhanced_study(
            study_name=study_name,
            direction="maximize",
            sampler=sampler
        )
        logger.info(f"âœ… åˆ›å»ºæ–°çš„ç ”ç©¶ {study_name} (ä½¿ç”¨å¢å¼ºå‹Rediså­˜å‚¨)")

    return study


def _run_first_stage_optimization(df, factors, num_factors, args, max_combinations, all_filter_conditions=None):
    """è¿è¡Œç¬¬ä¸€é˜¶æ®µä¼˜åŒ–ï¼ˆä¸“æ³¨å› å­ç»„åˆæ¢ç´¢ï¼‰

    Args:
        df: æ•°æ®æ¡†
        factors: å› å­åˆ—è¡¨
        num_factors: å› å­æ•°é‡
        args: å‚æ•°
        max_combinations: æœ€å¤§ç»„åˆæ•°é‡
        all_filter_conditions: æ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶

    Returns:
        first_stage_study: ç¬¬ä¸€é˜¶æ®µç ”ç©¶
        first_stage_combinations: ç¬¬ä¸€é˜¶æ®µå› å­ç»„åˆ
    """
    logger.info("\n===== ç¬¬ä¸€é˜¶æ®µï¼šæ¢ç´¢å› å­ç»„åˆ =====")

    # å‡†å¤‡å› å­ç»„åˆ
    first_stage_combinations = _prepare_first_stage_combinations(factors, num_factors, args, max_combinations)

    # åˆ›å»ºç¬¬ä¸€é˜¶æ®µç ”ç©¶
    # åŒ…å«æ‰€æœ‰å…³é”®å‚æ•°é¿å…æ•°æ®æ··åˆï¼Œæ·»åŠ æ—¶é—´æˆ³ç¡®ä¿æ¯æ¬¡è¿è¡Œç‹¬ç«‹
    filter_suffix = "filter" if getattr(args, 'enable_filter_opt', False) else "nofilter"
    timestamp = int(time.time())  # æ·»åŠ æ—¶é—´æˆ³ç¡®ä¿å”¯ä¸€æ€§
    args._optimization_timestamp = timestamp  # ä¿å­˜æ—¶é—´æˆ³ä¾›åç»­é˜¶æ®µä½¿ç”¨
    study_name = f"first_stage_{args.strategy}_{args.method}_{args.n_factors}factors_{args.start_date}_{args.end_date}_{args.price_min}_{args.price_max}_{args.hold_num}_{args.n_trials}trials_{filter_suffix}_{args.seed}_{timestamp}"
    first_stage_study = _create_study(study_name, args, "random")

    # è·å–max_filter_factorsé…ç½®ï¼ˆä¸€æ¬¡æ€§åŠ è½½ï¼Œé¿å…é‡å¤ï¼‰
    from lude.utils.filter_generator_optimized import OptimizedFilterFactorGenerator
    generator = OptimizedFilterFactorGenerator()
    max_filter_factors = generator.config.get('combination_rules', {}).get('max_factors', 6)

    # åˆ›å»ºç›®æ ‡å‡½æ•°ï¼ˆä½¿ç”¨æ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶ï¼‰
    objective_func = create_optimized_objective_function(df, first_stage_combinations, args, all_filter_conditions,
                                                         max_filter_factors)

    # æ‰§è¡Œç¬¬ä¸€é˜¶æ®µä¼˜åŒ–
    n_trials_first_stage = min(args.n_trials // 2, 2000)
    adjusted_n_jobs = max(1, min(args.n_jobs // 2, 10))

    try:
        logger.info(f"ç¬¬ä¸€é˜¶æ®µä¼˜åŒ–å¼€å§‹ï¼Œå…± {n_trials_first_stage} ä¸ªè¯•éªŒï¼Œä½¿ç”¨ {adjusted_n_jobs} ä¸ªè¿›ç¨‹")
        # ğŸš¨ å†…å­˜ä¼˜åŒ–ï¼šç›´æ¥è¿è¡Œï¼Œä»…åœ¨å¿…è¦æ—¶æ¸…ç†ï¼ˆä¿æŒä¼˜åŒ–è´¨é‡ï¼‰
        first_stage_study.optimize(
            objective_func, n_trials=n_trials_first_stage, n_jobs=adjusted_n_jobs, gc_after_trial=True
        )
        
        # è¿è¡Œå®Œæˆåæ£€æŸ¥å†…å­˜å¹¶æ¸…ç†ï¼ˆä¸æ‰“æ–­ä¼˜åŒ–è¿‡ç¨‹ï¼‰
        memory_status = check_memory_warning(warning_threshold=80.0, critical_threshold=90.0)
        if memory_status in ['warning', 'critical']:
            logger.info("ä¼˜åŒ–å®Œæˆåæ¸…ç†å†…å­˜...")
            import gc
            gc.collect()
            logger.info(f"ç¬¬ä¸€é˜¶æ®µä¼˜åŒ–å®Œæˆï¼Œå…± {len(first_stage_study.trials)} ä¸ªè¯•éªŒ")
            
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­äº†ç¬¬ä¸€é˜¶æ®µä¼˜åŒ–")
    except Exception as e:
        error_msg = str(e)
        logger.error(f"ç¬¬ä¸€é˜¶æ®µä¼˜åŒ–å‡ºé”™: {e}")
        
        # ğŸš¨ ä¸¥æ ¼å¤„ç†Redisè¿æ¥é”™è¯¯ - ä¸å…è®¸fallback
        if "Connection reset by peer" in error_msg or "redis" in error_msg.lower() or "socket" in error_msg.lower():
            logger.error("æ£€æµ‹åˆ°Redisè¿æ¥é—®é¢˜ï¼Œè¿™æ˜¯éœ€è¦ä¿®å¤çš„æ ¹æœ¬é—®é¢˜")
            logger.error("å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
            logger.error("1. æ£€æŸ¥RedisæœåŠ¡çŠ¶æ€: redis-cli ping")
            logger.error("2. æ£€æŸ¥Redisé…ç½®: è¶…æ—¶è®¾ç½®ã€è¿æ¥æ•°é™åˆ¶")
            logger.error("3. æ£€æŸ¥ç½‘ç»œè¿æ¥: netstat -an | grep 6379")
            logger.error("4. æ£€æŸ¥ç³»ç»Ÿèµ„æº: Rediså†…å­˜ä½¿ç”¨ã€æ–‡ä»¶æè¿°ç¬¦é™åˆ¶")
            logger.error("5. æŸ¥çœ‹Redisæ—¥å¿—: tail -f /var/log/redis/redis-server.log")
            
            # é‡æ–°æŠ›å‡ºåŸå§‹å¼‚å¸¸ï¼Œä¸è¿›è¡Œä»»ä½•é™çº§å¤„ç†
            raise

    return first_stage_study, first_stage_combinations


def _get_first_stage_results(first_stage_study, first_stage_combinations, _num_factors):
    """è·å–ç¬¬ä¸€é˜¶æ®µç»“æœï¼ŒåŒ…æ‹¬TOP 10ç»„åˆ

    Args:
        first_stage_study: ç¬¬ä¸€é˜¶æ®µç ”ç©¶
        first_stage_combinations: ç¬¬ä¸€é˜¶æ®µå› å­ç»„åˆ
        num_factors: å› å­æ•°é‡

    Returns:
        best_params: æœ€ä½³å‚æ•°
        best_value: æœ€ä½³å€¼
        best_combination: æœ€ä½³å› å­ç»„åˆ
        top_combinations_with_params: TOP 10ç»„åˆåŠå…¶å‚æ•°åˆ—è¡¨
    """
    # æ£€æŸ¥ç¬¬ä¸€é˜¶æ®µæ˜¯å¦æœ‰ç»“æœ
    if len(first_stage_study.trials) == 0:
        logger.error("ç¬¬ä¸€é˜¶æ®µæ²¡æœ‰å®Œæˆä»»ä½•è¯•éªŒï¼Œæ— æ³•ç»§ç»­")
        return None, None, None, []

    # è·å–ç¬¬ä¸€é˜¶æ®µæœ€ä½³ç»“æœ
    best_params = first_stage_study.best_params
    best_value = first_stage_study.best_value

    logger.info(f"\nç¬¬ä¸€é˜¶æ®µæœ€ä½³CAGR: {best_value:.6f}")

    # è·å–TOP 10ç»„åˆåŠå…¶å‚æ•°
    top_combinations_with_params = []
    if len(first_stage_study.trials) > 0:
        # æŒ‰CAGRå€¼æ’åºè·å–TOP 10
        valid_trials = [t for t in first_stage_study.trials if t.value is not None]
        sorted_trials = sorted(valid_trials, key=lambda t: t.value, reverse=True)
        top_trials = sorted_trials[:min(10, len(sorted_trials))]
        
        logger.info(f"\nç¬¬ä¸€é˜¶æ®µTOP {len(top_trials)} ç»„åˆ:")
        for idx, trial in enumerate(top_trials):
            if "combination_idx" in trial.params:
                combo_idx = trial.params["combination_idx"]
                combination = first_stage_combinations[combo_idx]
                
                # æ”¶é›†ç»„åˆåŠå…¶å‚æ•°ä¿¡æ¯
                combination_info = {
                    'combination': combination,
                    'params': trial.params,
                    'value': trial.value,
                    'user_attrs': trial.user_attrs
                }
                top_combinations_with_params.append(combination_info)
                
                # æ‰“å°åŸºæœ¬ä¿¡æ¯
                logger.info(f"  {idx + 1}. CAGR: {trial.value:.6f}, ç»„åˆ: {combination}")
                
                # æ‰“å°è¯¦ç»†çš„å› å­æƒé‡å’Œæ’åºæ–¹å‘ä¿¡æ¯
                logger.info(f"     è¯¦ç»†é…ç½®:")
                for i, factor in enumerate(combination):
                    weight_param = f"factor{i}_weight"
                    asc_param = f"factor{i}_ascending"
                    
                    weight = trial.params.get(weight_param, 1)
                    ascending = trial.params.get(asc_param, True)
                    direction = "å‡åº" if ascending else "é™åº"
                    
                    logger.info(f"       - {factor}: æƒé‡={weight}, æ–¹å‘={direction}")

    # æå–æœ€ä½³å› å­ç»„åˆ
    if "combination_idx" in best_params:
        best_combination_idx = best_params["combination_idx"]
        best_combination = first_stage_combinations[best_combination_idx]

        logger.info(f"ç¬¬ä¸€é˜¶æ®µæœ€ä½³å› å­ç»„åˆ (CAGR: {best_value:.6f}):")
        for i, factor in enumerate(best_combination):
            weight_param = f"factor{i}_weight"
            asc_param = f"factor{i}_ascending"

            weight = best_params.get(weight_param, 1)
            ascending = best_params.get(asc_param, True)

            direction = "å‡åº" if ascending else "é™åº"
            logger.info(f"  {i + 1}. {factor}")
            logger.info(f"     - æƒé‡: {weight}")
            logger.info(f"     - æ’åºæ–¹å‘: {direction}")

        return best_params, best_value, best_combination, top_combinations_with_params
    else:
        logger.warning("æ— æ³•è·å–ç¬¬ä¸€é˜¶æ®µæœ€ä½³å› å­ç»„åˆ")
        return None, None, None, top_combinations_with_params


def _prepare_second_stage_combinations_enhanced(factors, num_factors, top_combinations_with_params, max_combinations, args):
    """å¢å¼ºçš„ç¬¬äºŒé˜¶æ®µå› å­ç»„åˆå‡†å¤‡
    
    åŸºäºTOP 10ç»„åˆçš„å¤šç­–ç•¥ç”Ÿæˆï¼š
    1. æ·»åŠ TOP 10åŸå§‹ç»„åˆ
    2. å¯¹TOP 10è¿›è¡Œæ›¿æ¢1ä¸ªå› å­
    3. å¯¹TOP 10è¿›è¡Œæƒé‡è°ƒæ•´ (Â±1)
    4. æ§åˆ¶æ€»æ•°ä¸è¶…è¿‡max_combinations/2

    Args:
        factors: å› å­åˆ—è¡¨
        num_factors: å› å­æ•°é‡  
        top_combinations_with_params: TOP 10ç»„åˆåŠå…¶å‚æ•°ä¿¡æ¯
        max_combinations: æœ€å¤§ç»„åˆæ•°é‡
        args: å‚æ•°

    Returns:
        second_stage_combinations: ç¬¬äºŒé˜¶æ®µå› å­ç»„åˆåˆ—è¡¨
        second_stage_combination_details: ç»„åˆè¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«æƒé‡ç­‰ï¼‰
    """
    logger.info("å‡†å¤‡å¢å¼ºçš„ç¬¬äºŒé˜¶æ®µå› å­ç»„åˆ...")
    
    second_stage_combinations = []
    second_stage_combination_details = []
    combination_set = set()  # ç”¨äºå»é‡
    
    # é…ç½®é™åˆ¶
    max_second_stage = max_combinations // 2  # 50,000
    available_factors = [f for f in factors]  # æ‰€æœ‰å¯ç”¨å› å­
    
    logger.info(f"ç›®æ ‡ç»„åˆæ•°é‡ä¸Šé™: {max_second_stage}")
    logger.info(f"å¯ç”¨å› å­æ€»æ•°: {len(available_factors)}")
    logger.info(f"TOPç»„åˆæ•°é‡: {len(top_combinations_with_params)}")

    # ========== ç­–ç•¥1: æ·»åŠ TOP 10åŸå§‹ç»„åˆ ==========
    logger.info("ç­–ç•¥1: æ·»åŠ TOPç»„åˆ...")
    for combo_info in top_combinations_with_params:
        combination = combo_info['combination']
        combination_key = tuple(sorted(combination))
        
        if combination_key not in combination_set:
            second_stage_combinations.append(combination)
            second_stage_combination_details.append({
                'combination': combination,
                'source': 'top_original',
                'base_params': combo_info['params']
            })
            combination_set.add(combination_key)
    
    logger.info(f"ç­–ç•¥1å®Œæˆï¼Œå½“å‰ç»„åˆæ•°: {len(second_stage_combinations)}")

    # ========== ç­–ç•¥2: å¯¹TOP 10è¿›è¡Œæ›¿æ¢1ä¸ªå› å­ ==========
    logger.info("ç­–ç•¥2: æ›¿æ¢1ä¸ªå› å­...")
    for combo_info in top_combinations_with_params:
        if len(second_stage_combinations) >= max_second_stage:
            break
            
        base_combination = combo_info['combination']
        base_params = combo_info['params']
        
        # å¯¹æ¯ä¸ªä½ç½®å°è¯•æ›¿æ¢
        for i in range(num_factors):
            if len(second_stage_combinations) >= max_second_stage:
                break
                
            for factor in available_factors:
                if factor not in base_combination:  # é¿å…æ›¿æ¢æˆç›¸åŒå› å­
                    new_combination = list(base_combination)
                    new_combination[i] = factor
                    new_combination = tuple(new_combination)
                    combination_key = tuple(sorted(new_combination))
                    
                    if combination_key not in combination_set:
                        second_stage_combinations.append(new_combination)
                        second_stage_combination_details.append({
                            'combination': new_combination,
                            'source': 'factor_replacement',
                            'base_params': base_params,
                            'replaced_position': i,
                            'original_factor': base_combination[i],
                            'new_factor': factor
                        })
                        combination_set.add(combination_key)
    
    logger.info(f"ç­–ç•¥2å®Œæˆï¼Œå½“å‰ç»„åˆæ•°: {len(second_stage_combinations)}")

    # ========== ç­–ç•¥3: æƒé‡è°ƒæ•´å˜ä½“ ==========  
    logger.info("ç­–ç•¥3: æƒé‡è°ƒæ•´å˜ä½“...")
    weight_variants = []
    
    for combo_info in top_combinations_with_params:
        if len(weight_variants) >= max_second_stage // 4:  # é™åˆ¶æƒé‡å˜ä½“æ•°é‡
            break
            
        base_combination = combo_info['combination'] 
        base_params = combo_info['params']
        
        # ç­–ç•¥3A: ç³»ç»Ÿæ€§æƒé‡è°ƒæ•´ - å¯¹æ¯ä¸ªå› å­éƒ½å°è¯•Â±1
        for i in range(num_factors):
            weight_param = f"factor{i}_weight"
            original_weight = base_params.get(weight_param, 1)
            
            # +1 å˜ä½“
            if original_weight < 5:
                new_params = base_params.copy()
                new_params[weight_param] = original_weight + 1
                weight_variants.append({
                    'combination': base_combination,
                    'source': 'weight_systematic',
                    'base_params': new_params,
                    'adjustment': f"factor{i}_weight: {original_weight} -> {original_weight + 1}"
                })
            
            # -1 å˜ä½“  
            if original_weight > 1:
                new_params = base_params.copy()
                new_params[weight_param] = original_weight - 1
                weight_variants.append({
                    'combination': base_combination,
                    'source': 'weight_systematic', 
                    'base_params': new_params,
                    'adjustment': f"factor{i}_weight: {original_weight} -> {original_weight - 1}"
                })
        
        # ç­–ç•¥3B: éšæœºæƒé‡è°ƒæ•´ - éšæœºé€‰æ‹©1ä¸ªå› å­è¿›è¡ŒÂ±1è°ƒæ•´
        # ç¡®ä¿å¯é‡å¤æ€§ï¼Œä½¿ç”¨å®‰å…¨çš„ç§å­å€¼
        combo_hash = abs(hash(str(base_combination))) % (2**32 - 1)
        np.random.seed((args.seed + combo_hash) % (2**32 - 1))
        
        # ç”Ÿæˆå¤šä¸ªéšæœºæƒé‡å˜ä½“ï¼ˆæ¯ä¸ªTOPç»„åˆç”Ÿæˆ3-5ä¸ªéšæœºå˜ä½“ï¼‰
        num_random_variants = np.random.randint(3, 6)  # éšæœº3-5ä¸ªå˜ä½“
        
        for _ in range(num_random_variants):
            if len(weight_variants) >= max_second_stage // 4:
                break
                
            # éšæœºé€‰æ‹©ä¸€ä¸ªå› å­ä½ç½®
            random_factor_idx = np.random.randint(0, num_factors)
            weight_param = f"factor{random_factor_idx}_weight"
            original_weight = base_params.get(weight_param, 1)
            
            # éšæœºé€‰æ‹©+1æˆ–-1
            adjustment = np.random.choice([+1, -1])
            new_weight = original_weight + adjustment
            
            # æ£€æŸ¥æƒé‡èŒƒå›´åˆæ³•æ€§
            if 1 <= new_weight <= 5:
                new_params = base_params.copy()
                new_params[weight_param] = new_weight
                weight_variants.append({
                    'combination': base_combination,
                    'source': 'weight_random',
                    'base_params': new_params,
                    'adjustment': f"factor{random_factor_idx}_weight: {original_weight} -> {new_weight} (random)"
                })
    
    # æ·»åŠ æƒé‡å˜ä½“åˆ°æœ€ç»ˆåˆ—è¡¨
    for variant in weight_variants:
        if len(second_stage_combinations) >= max_second_stage:
            break
        second_stage_combinations.append(variant['combination'])
        second_stage_combination_details.append(variant)
    
    logger.info(f"ç­–ç•¥3å®Œæˆï¼Œå½“å‰ç»„åˆæ•°: {len(second_stage_combinations)}")

    # ========== æœ€ç»ˆæ§åˆ¶ï¼šç¡®ä¿ä¸è¶…è¿‡ä¸Šé™ ==========
    if len(second_stage_combinations) > max_second_stage:
        logger.info(f"ç»„åˆæ•°é‡({len(second_stage_combinations)})è¶…è¿‡ä¸Šé™({max_second_stage})ï¼Œè¿›è¡Œéšæœºé‡‡æ ·...")
        np.random.seed(args.seed)
        indices = np.random.choice(len(second_stage_combinations), max_second_stage, replace=False)
        second_stage_combinations = [second_stage_combinations[i] for i in indices]
        second_stage_combination_details = [second_stage_combination_details[i] for i in indices]

    logger.info(f"ç¬¬äºŒé˜¶æ®µæœ€ç»ˆå°†æ¢ç´¢ {len(second_stage_combinations)} ä¸ªå› å­ç»„åˆ")
    
    # ç»Ÿè®¡å„ç­–ç•¥è´¡çŒ®
    strategy_counts = {}
    for detail in second_stage_combination_details:
        source = detail['source']
        strategy_counts[source] = strategy_counts.get(source, 0) + 1
    
    logger.info("å„ç­–ç•¥è´¡çŒ®ç»Ÿè®¡:")
    for strategy, count in strategy_counts.items():
        logger.info(f"  {strategy}: {count} ä¸ªç»„åˆ")

    return second_stage_combinations, second_stage_combination_details


def _add_first_stage_best_to_second_stage(
        second_stage_study, first_stage_study, first_stage_best_params, first_stage_best_value, second_stage_combinations, num_factors
):
    """å°†ç¬¬ä¸€é˜¶æ®µæœ€ä½³ç»“æœæ·»åŠ åˆ°ç¬¬äºŒé˜¶æ®µç ”ç©¶ä¸­

    Args:
        second_stage_study: ç¬¬äºŒé˜¶æ®µç ”ç©¶
        first_stage_best_params: ç¬¬ä¸€é˜¶æ®µæœ€ä½³å‚æ•°
        first_stage_best_value: ç¬¬ä¸€é˜¶æ®µæœ€ä½³å€¼
        second_stage_combinations: ç¬¬äºŒé˜¶æ®µç»„åˆ
        num_factors: å› å­æ•°é‡
    """
    try:
        # è·å–ç¬¬ä¸€é˜¶æ®µæœ€ä½³ç»„åˆåœ¨ç¬¬äºŒé˜¶æ®µç»„åˆä¸­çš„ç´¢å¼•
        first_best_combination_idx = 0  # å·²ç»ç¡®ä¿ç¬¬ä¸€é˜¶æ®µæœ€ä½³ç»„åˆåœ¨ç¬¬äºŒé˜¶æ®µç»„åˆçš„ç¬¬ä¸€ä¸ªä½ç½®

        # åˆ›å»ºæ–°çš„å‚æ•°é›†åˆ
        new_params = {"combination_idx": first_best_combination_idx}

        # å¤åˆ¶æ‰€æœ‰å› å­å‚æ•°
        for i in range(num_factors):
            weight_param = f"factor{i}_weight"
            asc_param = f"factor{i}_ascending"
            if weight_param in first_stage_best_params:
                new_params[weight_param] = first_stage_best_params[weight_param]
            if asc_param in first_stage_best_params:
                new_params[asc_param] = first_stage_best_params[asc_param]

        # ğŸ¯ å¤åˆ¶æ’é™¤å› å­ç›¸å…³å‚æ•°
        for param_name, param_value in first_stage_best_params.items():
            if param_name.startswith("num_filter_conditions") or param_name.startswith("filter_condition_") or param_name == "filter_combo_idx":
                new_params[param_name] = param_value

        # åˆ›å»ºåˆ†å¸ƒå­—å…¸
        distributions = {}
        distributions["combination_idx"] = optuna.distributions.IntDistribution(0, len(second_stage_combinations) - 1)
        for i in range(num_factors):
            weight_param = f"factor{i}_weight"
            asc_param = f"factor{i}_ascending"
            distributions[weight_param] = optuna.distributions.IntDistribution(1, 5)
            distributions[asc_param] = optuna.distributions.CategoricalDistribution([True, False])

        # ğŸ¯ ä¿®å¤æ–¹æ¡ˆï¼šä¸ºæ’é™¤å› å­å‚æ•°åˆ›å»ºå›ºå®šçš„åˆ†å¸ƒ - é¿å…åŠ¨æ€è°ƒæ•´ç ´åå‚æ•°ç©ºé—´ä¸€è‡´æ€§
        from lude.utils.filter_generator_optimized import OptimizedFilterFactorGenerator
        generator = OptimizedFilterFactorGenerator()
        for param_name in new_params:
            if param_name.startswith("filter_condition_") and param_name.endswith("_idx"):
                # éœ€è¦è·å–all_filter_conditionsçš„é•¿åº¦ï¼Œä½†è¿™ä¸ªå‡½æ•°æ²¡æœ‰ä¼ å…¥è¯¥å‚æ•°
                # é‡æ–°ç”Ÿæˆæ¥è·å–æ­£ç¡®çš„èŒƒå›´
                config_factors = generator.get_available_factors()
                all_filter_conditions = []
                for factor_name in config_factors:
                    conditions = generator.generate_single_factor_conditions(factor_name)
                    all_filter_conditions.extend(conditions)
                
                if all_filter_conditions:
                    distributions[param_name] = optuna.distributions.IntDistribution(0, len(all_filter_conditions) - 1)
                else:
                    distributions[param_name] = optuna.distributions.IntDistribution(0, 0)
            elif param_name == "filter_combo_idx":
                # ç®€æ´å¤„ç†ï¼šfilter_combo_idxåœ¨objectiveå‡½æ•°ä¸­åŠ¨æ€å»ºè®®ï¼Œæ— éœ€é¢„è®¾å¤æ‚åˆ†å¸ƒ
                distributions[param_name] = optuna.distributions.IntDistribution(0, max(100, param_value))

        # è·å–ç¬¬ä¸€é˜¶æ®µæœ€ä½³trialçš„user_attrsï¼Œç¡®ä¿filter_conditionsè¢«æ­£ç¡®ä¼ é€’
        first_stage_user_attrs = first_stage_study.best_trial.user_attrs
        logger.info(f"è°ƒè¯•ï¼šç¬¬ä¸€é˜¶æ®µæœ€ä½³trialçš„user_attrs: {first_stage_user_attrs}")
        
        # åˆ›å»ºtrialå¹¶æ·»åŠ åˆ°ç ”ç©¶ä¸­ï¼Œä¿ç•™ç¬¬ä¸€é˜¶æ®µçš„user_attrs
        trial = optuna.trial.create_trial(
            params=new_params, 
            distributions=distributions, 
            value=first_stage_best_value,
            user_attrs=first_stage_user_attrs
        )
        second_stage_study.add_trial(trial)
        logger.info("æˆåŠŸå°†ç¬¬ä¸€é˜¶æ®µæœ€ä½³å‚æ•°ï¼ˆåŒ…æ‹¬user_attrsï¼‰æ·»åŠ åˆ°ç¬¬äºŒé˜¶æ®µç ”ç©¶ä¸­")
    except Exception as e:
        logger.error(f"æ·»åŠ ç¬¬ä¸€é˜¶æ®µæœ€ä½³å‚æ•°åˆ°ç¬¬äºŒé˜¶æ®µæ—¶å‡ºé”™: {e}")
        logger.warning("ç»§ç»­æ‰§è¡Œç¬¬äºŒé˜¶æ®µ...")


def _run_second_stage_optimization(
        df,
        factors,
        num_factors,
        args,
        first_stage_study,
        first_stage_best_params,
        first_stage_best_value,
        first_stage_combinations,
        top_combinations_with_params,
        max_combinations,
        all_filter_conditions=None,
):
    """è¿è¡Œç¬¬äºŒé˜¶æ®µä¼˜åŒ–ï¼ˆä¸“æ³¨æƒé‡å’Œæ’åºæ–¹å‘ä¼˜åŒ–ï¼‰

    Args:
        df: æ•°æ®æ¡†
        factors: å› å­åˆ—è¡¨
        num_factors: å› å­æ•°é‡
        args: å‚æ•°
        first_stage_best_params: ç¬¬ä¸€é˜¶æ®µæœ€ä½³å‚æ•°
        first_stage_best_value: ç¬¬ä¸€é˜¶æ®µæœ€ä½³å€¼
        first_stage_combinations: ç¬¬ä¸€é˜¶æ®µå› å­ç»„åˆ
        max_combinations: æœ€å¤§ç»„åˆæ•°é‡
        all_filter_conditions: æ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶

    Returns:
        second_stage_study: ç¬¬äºŒé˜¶æ®µç ”ç©¶
        second_stage_combinations: ç¬¬äºŒé˜¶æ®µå› å­ç»„åˆ
    """
    logger.info("\n===== ç¬¬äºŒé˜¶æ®µï¼šä¼˜åŒ–æƒé‡å’Œæ’åºæ–¹å‘ =====")

    # ä½¿ç”¨å¢å¼ºçš„ç¬¬äºŒé˜¶æ®µç»„åˆå‡†å¤‡ï¼ˆåŸºäºTOP 10ç»„åˆï¼‰
    second_stage_combinations, second_stage_combination_details = _prepare_second_stage_combinations_enhanced(
        factors, num_factors, top_combinations_with_params, max_combinations, args
    )

    # åˆ›å»ºç¬¬äºŒé˜¶æ®µç ”ç©¶  
    # åŒ…å«æ‰€æœ‰å…³é”®å‚æ•°é¿å…æ•°æ®æ··åˆï¼Œä½¿ç”¨ç›¸åŒæ—¶é—´æˆ³ä¿æŒä¸€è‡´æ€§
    filter_suffix = "filter" if getattr(args, 'enable_filter_opt', False) else "nofilter"
    # ä½¿ç”¨ä¸ç¬¬ä¸€é˜¶æ®µç›¸åŒçš„æ—¶é—´æˆ³ï¼Œä¿æŒå¤šé˜¶æ®µç ”ç©¶çš„å…³è”æ€§
    timestamp = getattr(args, '_optimization_timestamp', int(time.time()))
    study_name = f"second_stage_{args.strategy}_{args.method}_{args.n_factors}factors_{args.start_date}_{args.end_date}_{args.price_min}_{args.price_max}_{args.hold_num}_{args.n_trials}trials_{filter_suffix}_{args.seed}_{timestamp}"
    second_stage_study = _create_study(study_name, args, args.method)

    # å°†ç¬¬ä¸€é˜¶æ®µæœ€ä½³ç»“æœæ·»åŠ åˆ°ç¬¬äºŒé˜¶æ®µ
    _add_first_stage_best_to_second_stage(
        second_stage_study, first_stage_study, first_stage_best_params, first_stage_best_value, second_stage_combinations, num_factors
    )

    # è·å–max_filter_factorsé…ç½®ï¼ˆå¤ç”¨ç¬¬ä¸€é˜¶æ®µçš„é…ç½®ï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
    from lude.utils.filter_generator_optimized import OptimizedFilterFactorGenerator
    generator = OptimizedFilterFactorGenerator()
    max_filter_factors = generator.config.get('combination_rules', {}).get('max_factors', 6)

    # åˆ›å»ºç›®æ ‡å‡½æ•°ï¼ˆä½¿ç”¨æ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶ï¼‰
    objective_func = create_optimized_objective_function(df, second_stage_combinations, args, all_filter_conditions,
                                                         max_filter_factors)

    # æ‰§è¡Œç¬¬äºŒé˜¶æ®µä¼˜åŒ–
    n_trials_first_stage = min(args.n_trials // 2, 2000)
    n_trials_second_stage = args.n_trials - n_trials_first_stage
    adjusted_n_jobs = max(1, min(args.n_jobs // 2, 10))
    
    try:
        logger.info(f"ç¬¬äºŒé˜¶æ®µä¼˜åŒ–å¼€å§‹ï¼Œå…± {n_trials_second_stage} ä¸ªè¯•éªŒï¼Œä½¿ç”¨ {adjusted_n_jobs} ä¸ªè¿›ç¨‹")
        # ğŸš¨ å†…å­˜ä¼˜åŒ–ï¼šç›´æ¥è¿è¡Œç¬¬äºŒé˜¶æ®µï¼Œä¿æŒä¼˜åŒ–è´¨é‡
        second_stage_study.optimize(
            objective_func, n_trials=n_trials_second_stage, n_jobs=adjusted_n_jobs, gc_after_trial=True
        )
        
        # ç¬¬äºŒé˜¶æ®µå®Œæˆåæ¸…ç†å†…å­˜
        memory_status = check_memory_warning(warning_threshold=80.0, critical_threshold=90.0)
        if memory_status in ['warning', 'critical']:
            logger.info("ç¬¬äºŒé˜¶æ®µä¼˜åŒ–å®Œæˆåæ¸…ç†å†…å­˜...")
            import gc
            gc.collect()
            logger.info(f"ç¬¬äºŒé˜¶æ®µä¼˜åŒ–å®Œæˆï¼Œå…± {len(second_stage_study.trials)} ä¸ªè¯•éªŒ")
                
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­äº†ç¬¬äºŒé˜¶æ®µä¼˜åŒ–")
    except Exception as e:
        logger.error(f"ç¬¬äºŒé˜¶æ®µä¼˜åŒ–å‡ºé”™: {e}")

    return second_stage_study, second_stage_combinations


def _build_rank_factors(best_params, combinations, _num_factors):
    """é‡å»ºrank_factors

    Args:
        best_params: æœ€ä½³å‚æ•°
        combinations: å› å­ç»„åˆ
        num_factors: å› å­æ•°é‡

    Returns:
        rank_factors: é‡å»ºçš„rank_factorsåˆ—è¡¨
    """
    combination_idx = best_params["combination_idx"]
    combination = combinations[combination_idx]

    rank_factors = []
    for i, factor in enumerate(combination):
        weight_param = f"factor{i}_weight"
        asc_param = f"factor{i}_ascending"

        factor_info = {
            "name": factor,
            "weight": best_params.get(weight_param, 1),
            "ascending": best_params.get(asc_param, True),
        }
        rank_factors.append(factor_info)

    return rank_factors


def _create_final_study_and_merge_results(
        args,
        first_stage_study,
        first_stage_combinations,
        second_stage_study,
        second_stage_combinations,
        first_stage_best_value,
        num_factors,
        all_filter_conditions=None,
):
    """åˆ›å»ºæœ€ç»ˆç ”ç©¶å¹¶åˆå¹¶ç»“æœ

    Args:
        args: å‚æ•°
        first_stage_study: ç¬¬ä¸€é˜¶æ®µç ”ç©¶
        first_stage_combinations: ç¬¬ä¸€é˜¶æ®µç»„åˆ
        second_stage_study: ç¬¬äºŒé˜¶æ®µç ”ç©¶
        second_stage_combinations: ç¬¬äºŒé˜¶æ®µç»„åˆ
        first_stage_best_value: ç¬¬ä¸€é˜¶æ®µæœ€ä½³å€¼
        num_factors: å› å­æ•°é‡
        all_filter_conditions: æ‰€æœ‰æ’é™¤å› å­æ¡ä»¶åˆ—è¡¨

    Returns:
        final_study: æœ€ç»ˆç ”ç©¶
        all_combinations: æ‰€æœ‰ç»„åˆ
    """
    # åˆ›å»ºæœ€ç»ˆç ”ç©¶
    # åŒ…å«æ‰€æœ‰å…³é”®å‚æ•°é¿å…æ•°æ®æ··åˆï¼Œä½¿ç”¨ç›¸åŒæ—¶é—´æˆ³ä¿æŒä¸€è‡´æ€§
    filter_suffix = "filter" if getattr(args, 'enable_filter_opt', False) else "nofilter"
    # ä½¿ç”¨ä¸å‰ä¸¤é˜¶æ®µç›¸åŒçš„æ—¶é—´æˆ³
    timestamp = getattr(args, '_optimization_timestamp', int(time.time()))
    study_name = f"final_{args.strategy}_{args.method}_{args.n_factors}factors_{args.start_date}_{args.end_date}_{args.price_min}_{args.price_max}_{args.hold_num}_{args.n_trials}trials_{filter_suffix}_{args.seed}_{timestamp}"
    final_study = _create_study(study_name, args, args.method)

    # æ¯”è¾ƒä¸¤ä¸ªé˜¶æ®µçš„ç»“æœ
    second_stage_best_value = second_stage_study.best_value if len(second_stage_study.trials) > 0 else -float("inf")
    value_diff = second_stage_best_value - first_stage_best_value

    # å†³å®šä½¿ç”¨å“ªä¸ªé˜¶æ®µçš„ç»“æœ
    if abs(value_diff) < 0.0001:
        logger.info(f"ç¬¬äºŒé˜¶æ®µç»“æœ ({second_stage_best_value:.6f}) ä¸ç¬¬ä¸€é˜¶æ®µ ({first_stage_best_value:.6f}) åŸºæœ¬ç›¸åŒ")
        logger.info("ä½¿ç”¨ç¬¬äºŒé˜¶æ®µçš„æœ€ä½³ç»“æœ")
        use_second_stage = True
    elif value_diff < 0:
        logger.info(f"ç¬¬ä¸€é˜¶æ®µç»“æœ ({first_stage_best_value:.6f}) ä¼˜äºç¬¬äºŒé˜¶æ®µ ({second_stage_best_value:.6f})")
        logger.info("ä½¿ç”¨ç¬¬ä¸€é˜¶æ®µçš„æœ€ä½³ç»“æœ")
        use_second_stage = False
    else:
        logger.info(f"ç¬¬äºŒé˜¶æ®µç»“æœ ({second_stage_best_value:.6f}) ä¼˜äºç¬¬ä¸€é˜¶æ®µ ({first_stage_best_value:.6f})")
        logger.info("ä½¿ç”¨ç¬¬äºŒé˜¶æ®µçš„æœ€ä½³ç»“æœ")
        use_second_stage = True

    # æ ¹æ®é€‰æ‹©æ·»åŠ æœ€ä½³ç»“æœåˆ°æœ€ç»ˆç ”ç©¶
    if use_second_stage:
        best_study = second_stage_study
        best_combinations = second_stage_combinations
        best_value = second_stage_best_value
    else:
        best_study = first_stage_study
        best_combinations = first_stage_combinations
        best_value = first_stage_best_value

    # é‡å»ºrank_factorså¹¶æ·»åŠ åˆ°æœ€ç»ˆç ”ç©¶
    try:
        best_params = best_study.best_params
        rank_factors = _build_rank_factors(best_params, best_combinations, num_factors)

        # åˆ›å»ºåˆ†å¸ƒå­—å…¸ï¼Œå®Œå…¨åŒ¹é…best_paramsä¸­çš„å‚æ•°
        distributions = {}
        for param_name, param_value in best_params.items():
            if param_name == "combination_idx":
                distributions[param_name] = optuna.distributions.IntDistribution(0, len(best_combinations) - 1)
            elif param_name.endswith("_weight"):
                distributions[param_name] = optuna.distributions.IntDistribution(1, 5)
            elif param_name.endswith("_ascending"):
                distributions[param_name] = optuna.distributions.CategoricalDistribution([True, False])
            elif param_name == "use_filter":
                distributions[param_name] = optuna.distributions.CategoricalDistribution([True, False])
            elif param_name.startswith("filter_condition_") and param_name.endswith("_idx"):
                # ğŸ¯ å…³é”®ä¿®å¤ï¼šä½¿ç”¨å›ºå®šçš„åˆ†å¸ƒèŒƒå›´ï¼Œä¸æ ¹æ®å‚æ•°å€¼åŠ¨æ€è°ƒæ•´
                if all_filter_conditions:
                    # ä½¿ç”¨å›ºå®šçš„åˆ†å¸ƒèŒƒå›´ï¼Œä¿æŒå‚æ•°ç©ºé—´ä¸€è‡´æ€§
                    distributions[param_name] = optuna.distributions.IntDistribution(0, len(all_filter_conditions) - 1)
                else:
                    distributions[param_name] = optuna.distributions.IntDistribution(0, 0)
            elif param_name == "filter_combo_idx":
                # ç®€æ´å¤„ç†ï¼šfilter_combo_idxåœ¨objectiveå‡½æ•°ä¸­åŠ¨æ€å»ºè®®ï¼Œæ— éœ€é¢„è®¾å¤æ‚åˆ†å¸ƒ
                distributions[param_name] = optuna.distributions.IntDistribution(0, max(100, param_value))
            else:
                # å…¶ä»–å‚æ•°ç±»å‹å¤„ç†
                if isinstance(param_value, int):
                    # ğŸš¨ å®‰å…¨ä¿®å¤ï¼šç¡®ä¿èŒƒå›´åŒ…å«å½“å‰å‚æ•°å€¼
                    max_range = max(100, param_value)
                    distributions[param_name] = optuna.distributions.IntDistribution(0, max_range)
                elif isinstance(param_value, bool):
                    distributions[param_name] = optuna.distributions.CategoricalDistribution([True, False])
                else:
                    logger.warning(f"æœªçŸ¥å‚æ•°ç±»å‹: {param_name} = {param_value}")

        # è·å–åŸå§‹trialçš„filter_conditions
        original_filter_conditions = best_study.best_trial.user_attrs.get('filter_conditions', [])
        logger.info(f"è°ƒè¯•ï¼šä»åŸå§‹trialè·å–çš„filter_conditions: {original_filter_conditions}")
        
        # åˆ›å»ºæœ€ç»ˆtrialï¼Œä¿å­˜å®Œæ•´çš„user_attrs
        user_attrs = {
            "rank_factors": rank_factors,
            "filter_conditions": original_filter_conditions
        }
        trial = optuna.trial.create_trial(
            params=best_params, distributions=distributions, value=best_value, user_attrs=user_attrs
        )
        final_study.add_trial(trial)

        # ç›´æ¥æ·»åŠ å±æ€§ç¡®ä¿èƒ½è¢«è·å–åˆ°ï¼ˆå¤‡ç”¨æœºåˆ¶ï¼‰
        setattr(final_study, "best_rank_factors", rank_factors)
        setattr(final_study, "best_filter_conditions", original_filter_conditions)

        # æ‰“å°æœ€ä½³ç»“æœ
        logger.info(f"\næœ€ä½³å› å­ç»„åˆ (CAGR: {best_value:.6f}):")
        logger.info("ğŸ“Š æ‰“åˆ†å› å­:")
        for i, factor in enumerate(rank_factors):
            logger.info(f"  {i + 1}. {factor['name']}")
            logger.info(f"     - æƒé‡: {factor['weight']}")
            logger.info(f"     - æ’åºæ–¹å‘: {'å‡åº' if factor['ascending'] else 'é™åº'}")

        # æ‰“å°æ’é™¤å› å­ä¿¡æ¯
        try:
            # è°ƒè¯•ä¿¡æ¯ï¼šæŸ¥çœ‹final_studyæœ€ä½³trialçš„æ‰€æœ‰user_attrs
            logger.info(f"è°ƒè¯•ï¼šfinal_studyæœ€ä½³trialçš„æ‰€æœ‰user_attrs: {final_study.best_trial.user_attrs}")
            
            best_filter_conditions = final_study.best_trial.user_attrs.get('filter_conditions', [])
            logger.info(f"è°ƒè¯•ï¼šä»final_studyè·å–åˆ°çš„best_filter_conditions: {best_filter_conditions}")
            
            if best_filter_conditions:
                logger.info("ğŸš« æ’é™¤å› å­:")
                for i, condition in enumerate(best_filter_conditions):
                    logger.info(f"  {i + 1}. {condition['factor']} {condition['operator']} {condition['value']}")
            else:
                logger.info("ğŸš« æ’é™¤å› å­: æ— ")
        except Exception as filter_e:
            logger.warning(f"è·å–æ’é™¤å› å­ä¿¡æ¯æ—¶å‡ºé”™: {filter_e}")
            logger.info("\nğŸš« æ’é™¤å› å­: æ— æ³•è·å–")

    except Exception as e:
        logger.error(f"åˆ›å»ºæœ€ç»ˆç ”ç©¶æ—¶å‡ºé”™: {e}")
        raise e

    # è¿”å›æ‰€æœ‰æ¢ç´¢è¿‡çš„å› å­ç»„åˆ
    all_combinations = list(set(first_stage_combinations + second_stage_combinations))
    return final_study, all_combinations


def multistage_optimization(df, factors, num_factors, args, max_combinations=50000, enable_filter_opt=False):
    """ä¼˜åŒ–åçš„å¤šé˜¶æ®µä¼˜åŒ–ç­–ç•¥

    é¢„å¤„ç†é˜¶æ®µï¼šç¡®å®šè¿‡æ»¤æ¡ä»¶
    ç¬¬ä¸€é˜¶æ®µï¼šä¸“æ³¨å› å­ç»„åˆæ¢ç´¢
    ç¬¬äºŒé˜¶æ®µï¼šä¸“æ³¨æƒé‡å’Œæ’åºæ–¹å‘ä¼˜åŒ–

    Args:
        df: æ•°æ®æ¡†
        factors: å› å­åˆ—è¡¨
        num_factors: å› å­æ•°é‡
        args: å‚æ•°
        max_combinations: æœ€å¤§ç»„åˆæ•°é‡
        enable_filter_opt: æ˜¯å¦å¯ç”¨è¿‡æ»¤å› å­ç»„åˆä¼˜åŒ–

    Returns:
        factors: å› å­åˆ—è¡¨
        combinations: æ‰€æœ‰æ¢ç´¢è¿‡çš„å› å­ç»„åˆ
        final_study: æœ€ç»ˆçš„ä¼˜åŒ–ç ”ç©¶
    """
    logger.info(f"æ‰§è¡Œä¼˜åŒ–åçš„å¤šé˜¶æ®µä¼˜åŒ–ç­–ç•¥...")
    
    # ğŸš¨ å†…å­˜ç›‘æ§ï¼šè®°å½•ä¼˜åŒ–å¼€å§‹æ—¶çš„å†…å­˜çŠ¶æ€
    logger.info("å¼€å§‹å¤šé˜¶æ®µä¼˜åŒ–ï¼Œè®°å½•åˆå§‹å†…å­˜çŠ¶æ€:")
    log_memory_stats()

    # é¢„å¤„ç†é˜¶æ®µï¼šç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶
    logger.info("\n===== é¢„å¤„ç†é˜¶æ®µï¼šç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„æ’é™¤å› å­æ¡ä»¶ =====")
    all_filter_conditions = _prepare_all_filter_conditions(df, enable_filter_opt)

    # ç¬¬ä¸€é˜¶æ®µï¼šä¸“æ³¨å› å­ç»„åˆæ¢ç´¢
    first_stage_study, first_stage_combinations = _run_first_stage_optimization(
        df, factors, num_factors, args, max_combinations, all_filter_conditions
    )

    # è·å–ç¬¬ä¸€é˜¶æ®µç»“æœï¼ŒåŒ…æ‹¬TOP 10ç»„åˆ
    first_stage_best_params, first_stage_best_value, _, top_combinations_with_params = _get_first_stage_results(
        first_stage_study, first_stage_combinations, num_factors
    )

    if first_stage_best_params is None:
        logger.warning("ç¬¬ä¸€é˜¶æ®µæœ€ä½³å‚æ•°ä¸ºç©ºï¼Œè·³è¿‡ç¬¬äºŒé˜¶æ®µä¼˜åŒ–")
        return factors, first_stage_combinations, first_stage_study

    # ç¬¬äºŒé˜¶æ®µï¼šä¸“æ³¨æƒé‡å’Œæ’åºæ–¹å‘ä¼˜åŒ–
    second_stage_study, second_stage_combinations = _run_second_stage_optimization(
        df,
        factors,
        num_factors,
        args,
        first_stage_study,
        first_stage_best_params,
        first_stage_best_value,
        first_stage_combinations,
        top_combinations_with_params,
        max_combinations,
        all_filter_conditions,
    )

    # åˆ›å»ºæœ€ç»ˆç ”ç©¶å¹¶åˆå¹¶ç»“æœ
    final_study, all_combinations = _create_final_study_and_merge_results(
        args,
        first_stage_study,
        first_stage_combinations,
        second_stage_study,
        second_stage_combinations,
        first_stage_best_value,
        num_factors,
        all_filter_conditions,
    )

    return factors, all_combinations, final_study
