#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import argparse
import joblib
from datetime import datetime
import time
import subprocess
import json
import glob
import importlib.util
import threading
import sys
import re
from lude.utils.logger import optimization_logger as logger

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿Pythonè¾“å‡ºä¸è¢«ç¼“å­˜
os.environ['PYTHONUNBUFFERED'] = '1'

from lude.config.paths import RESULTS_DIR  # å¯¼å…¥ç»“æœç›®å½•å¸¸é‡

# ç»“æœå­˜å‚¨ç›®å½•
BEST_MODELS_DIR = os.path.join(RESULTS_DIR, "best_models")
os.makedirs(BEST_MODELS_DIR, exist_ok=True)

# å…¨å±€æœ€ä½³ç»“æœè·Ÿè¸ªæ–‡ä»¶
BEST_RECORD_FILE = os.path.join(RESULTS_DIR, "best_record.json")

# å…¨å±€å˜é‡ï¼Œé¿å…é¢‘ç¹æ–‡ä»¶è¯»å†™
global_best_record = {"best_cagr": 0, "best_model_path": "", "timestamp": ""}

def load_best_record():
    """åŠ è½½å†å²æœ€ä½³è®°å½•"""
    global global_best_record
    if os.path.exists(BEST_RECORD_FILE):
        with open(BEST_RECORD_FILE, 'r', encoding='utf-8') as f:
            try:
                loaded_record = json.load(f)
                
                # å‘åå…¼å®¹ï¼šå¦‚æœæ˜¯æ—§æ ¼å¼ï¼ˆä½¿ç”¨factorså­—æ®µï¼‰ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼
                if 'factors' in loaded_record and 'rank_factors' not in loaded_record:
                    loaded_record['rank_factors'] = loaded_record.pop('factors')
                    logger.info("å·²å°†æ—§æ ¼å¼çš„factorså­—æ®µè½¬æ¢ä¸ºrank_factors")
                
                # å¦‚æœæ²¡æœ‰filter_conditionså­—æ®µï¼Œæ·»åŠ ç©ºæ•°ç»„
                if 'filter_conditions' not in loaded_record:
                    loaded_record['filter_conditions'] = []
                    logger.info("ä¸ºå†å²è®°å½•æ·»åŠ ç©ºçš„filter_conditionså­—æ®µ")
                
                global_best_record = loaded_record
                return global_best_record
            except:
                return {"best_cagr": 0, "best_model_path": "", "timestamp": ""}
    return {"best_cagr": 0, "best_model_path": "", "timestamp": ""}

def save_best_record(record):
    """ä¿å­˜æœ€ä½³è®°å½•"""
    global global_best_record
    global_best_record = record
    with open(BEST_RECORD_FILE, 'w', encoding='utf-8') as f:
        json.dump(record, f, indent=4, ensure_ascii=False)

def find_latest_model(pattern=None):
    """æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶
    
    Args:
        pattern: æ–‡ä»¶ååŒ¹é…æ¨¡å¼ï¼Œé»˜è®¤æŸ¥æ‰¾æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
        
    Returns:
        æœ€æ–°æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
    """
    if pattern is None:
        # é»˜è®¤æŸ¥æ‰¾æ‰€æœ‰joblibæ–‡ä»¶
        pattern = "*.joblib"
    
    files = glob.glob(os.path.join(RESULTS_DIR, pattern))
    if files:
        return max(files, key=os.path.getctime)
    return None

def extract_cagr_from_output(output):
    """ä»è¾“å‡ºä¸­æå–CAGRå€¼"""
    try:
        # æŸ¥æ‰¾å¤šé˜¶æ®µä¼˜åŒ–çš„ç¬¬äºŒé˜¶æ®µç»“æœ
        second_stage_cagr = 0.0
        for line in output.split('\n'):
            if "ç¬¬äºŒé˜¶æ®µç»“æœ" in line and ("ä¼˜äºç¬¬ä¸€é˜¶æ®µ" in line or "åŸºæœ¬ç›¸åŒ" in line):
                try:
                    # æå–æ ¼å¼ä¸º"ç¬¬äºŒé˜¶æ®µç»“æœ (0.2702) ä¼˜äºç¬¬ä¸€é˜¶æ®µ (0.2215)"æˆ–"ç¬¬äºŒé˜¶æ®µç»“æœ (0.391601) ä¸ç¬¬ä¸€é˜¶æ®µ (0.391601) åŸºæœ¬ç›¸åŒ"ä¸­çš„ç¬¬ä¸€ä¸ªæ‹¬å·å†…æ•°å­—
                    match = re.search(r"ç¬¬äºŒé˜¶æ®µç»“æœ \(([0-9.]+)\)", line)
                    if match:
                        second_stage_cagr = float(match.group(1))
                        logger.info(f"æˆåŠŸæå–ç¬¬äºŒé˜¶æ®µCAGR: {second_stage_cagr}")
                except Exception as e:
                    logger.error(f"æå–ç¬¬äºŒé˜¶æ®µCAGRæ—¶å‡ºé”™: {e}")
        
        if second_stage_cagr > 0:
            return second_stage_cagr
            
        # ä¼˜å…ˆæŸ¥æ‰¾"æœ€ä½³å¹´åŒ–æ”¶ç›Šç‡"ï¼ˆæœ€ç»ˆç»“æœï¼‰
        final_cagr = 0.0
        for line in output.split('\n'):
            if "æœ€ä½³å¹´åŒ–æ”¶ç›Šç‡" in line:
                try:
                    cagr_value = float(line.split(":")[1].strip())
                    # è®°å½•æ‰¾åˆ°çš„æœ€å¤§CAGRå€¼
                    final_cagr = max(final_cagr, cagr_value)
                except:
                    pass
        
        if final_cagr > 0:
            return final_cagr
            
        # å¦‚æœæ²¡æ‰¾åˆ°æ ‡å‡†æ ¼å¼ï¼Œå°è¯•æŸ¥æ‰¾"best_value"
        for line in output.split('\n'):
            if "Best value:" in line:
                try:
                    cagr_str = line.split("Best value:")[1].split(":")[0].strip()
                    return float(cagr_str)
                except:
                    pass
    except Exception as e:
        logger.error(f"æå–CAGRæ—¶å‡ºé”™: {e}")
        return 0
    
    return 0


def show_progress(seconds=10):
    """æ˜¾ç¤ºç®€å•çš„è¿›åº¦æŒ‡ç¤ºå™¨"""
    chars = "|/-\\"
    for i in range(seconds * 2):
        sys.stdout.write('\r' + f"æ‰§è¡Œä¸­... {chars[i % 4]} ")
        sys.stdout.flush()
        time.sleep(0.5)
    print("\r" + " " * 30, end="\r")

def run_continuous_optimization(iterations=10, strategy="multistage", method="tpe", n_trials=3000, 
                     n_factors=3, start_date="20220729", end_date="20250328", 
                     price_min=100, price_max=150, hold_num=5, n_jobs=15,
                     seed_start=42, seed_step=1000, workspace_id='', enable_filter_opt=False):
    """è¿è¡Œè¿ç»­ä¼˜åŒ–è¿‡ç¨‹ï¼Œä½¿ç”¨æ”¹è¿›çš„ä½å¼€é”€æ–¹æ³•
    
    Args:
        iterations: ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
        strategy: ä¼˜åŒ–ç­–ç•¥(multistage, domain, prescreen, filter)
        method: ä¼˜åŒ–æ–¹æ³•(tpe, random, cmaes)
        n_trials: æ¯æ¬¡ä¼˜åŒ–çš„è¿­ä»£æ¬¡æ•°
        n_factors: å› å­æ•°é‡
        start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
        end_date: å›æµ‹ç»“æŸæ—¥æœŸ
        price_min: ä»·æ ¼ä¸‹é™
        price_max: ä»·æ ¼ä¸Šé™
        hold_num: æŒä»“æ•°é‡
        n_jobs: å¹¶è¡Œä»»åŠ¡æ•°
        seed_start: èµ·å§‹ç§å­å€¼
        seed_step: ç§å­é€’å¢æ­¥é•¿
        workspace_id: å·¥ä½œåŒºIDæ ‡è¯†
        enable_filter_opt: æ˜¯å¦å¯ç”¨è¿‡æ»¤å› å­ç»„åˆä¼˜åŒ–
    """
    
    # åŠ è½½æœ€ä½³è®°å½•
    best_record = load_best_record()
    logger.info(f"å†å²æœ€ä½³CAGR: {best_record['best_cagr']:.6f}, è®°å½•æ—¶é—´: {best_record['timestamp']}")
    
    # å‡†å¤‡åŸºç¡€ä¼˜åŒ–å‚æ•°ï¼ˆä¸åŒ…å«ç§å­ï¼‰
    base_params = {
        "strategy": strategy,
        "method": method,
        "n_trials": n_trials,
        "n_factors": n_factors,
        "start_date": start_date,
        "end_date": end_date,
        "price_min": price_min,
        "price_max": price_max,
        "hold_num": hold_num,
        "n_jobs": n_jobs,
        "workspace_id": workspace_id,
        "enable_filter_opt": enable_filter_opt
    }
    
    # è¿è¡Œå¤šæ¬¡ä¼˜åŒ–
    total_start_time = time.time()
    for i in range(iterations):
        # ä½¿ç”¨è§„å¾‹å˜åŒ–çš„ç§å­
        current_seed = seed_start + i * seed_step
        
        logger.info(f"============== ç¬¬ {i+1}/{iterations} æ¬¡ä¼˜åŒ– (ç§å­: {current_seed}) ==============")
        
        # æ›´æ–°å‚æ•°
        current_params = base_params.copy()
        current_params["seed"] = current_seed
        
        # å¼€å§‹è®¡æ—¶
        start_time = time.time()
        
        # æ˜¾ç¤ºæ‰§è¡Œä¿¡æ¯
        param_str = " ".join([f"--{k} {v}" for k, v in current_params.items()])
        logger.info(f"æ‰§è¡Œä¼˜åŒ–ï¼Œå‚æ•°: {param_str}")
        logger.info("æ­£åœ¨æ‰§è¡Œ...")
        logger.info("-" * 50)
        
        output = ""
        current_cagr = 0
        
        # å®šä¹‰è¿›åº¦æ˜¾ç¤ºçº¿ç¨‹
        stop_timer = False
        
        def show_elapsed_time():
            """æ˜¾ç¤ºå·²æ‰§è¡Œçš„æ—¶é—´"""
            elapsed = 0
            while not stop_timer:
                elapsed += 1
                print(f"\rå·²æ‰§è¡Œ {elapsed} ç§’...", end="")
                sys.stdout.flush()
                time.sleep(1)
        
        # å¯åŠ¨è®¡æ—¶å™¨çº¿ç¨‹
        timer_thread = threading.Thread(target=show_elapsed_time)
        timer_thread.daemon = True
        timer_thread.start()
        
        try:
            # ä½¿ç”¨å­è¿›ç¨‹æ–¹å¼æ‰§è¡Œï¼Œæ›´ç¨³å®šå¯é 
            # æ³¨æ„ï¼šä½¿ç”¨æ¨¡å—åŒ–è·¯å¾„ (-m) è€Œä¸æ˜¯ç›´æ¥è°ƒç”¨æ–‡ä»¶
            cmd = ["python", "-m", "lude.optimization.unified_optimizer", "--mode", "single"]
            for key, value in current_params.items():
                if key == "enable_filter_opt":
                    # ç‰¹æ®Šå¤„ç†ï¼šenable_filter_opt ä¸º store_true ç±»å‹ï¼Œåªæœ‰ä¸º True æ—¶æ‰æ·»åŠ å‚æ•°
                    if value:
                        cmd.append("--enable_filter_opt")
                else:
                    # æ™®é€šå‚æ•°ï¼šç›´æ¥æ·»åŠ  key å’Œ value
                    cmd.extend([f"--{key}", str(value)])
                
            # æ‰“å°å®Œæ•´å‘½ä»¤ç”¨äºè°ƒè¯•
            logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            # è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´ï¼Œæ ¹æ®è¯•éªŒæ¬¡æ•°å’Œå¹¶å‘æ•°åŠ¨æ€è°ƒæ•´
            # åŸºç¡€è¶…æ—¶æ—¶é—´ï¼š2å°æ—¶ï¼Œå¯¹äºå¤§é‡è¯•éªŒå¢åŠ æ—¶é—´
            base_timeout = 7200  # 2å°æ—¶
            trials_factor = min(current_params.get('n_trials', 1000) / 1000, 3)  # æœ€å¤š3å€
            jobs_factor = min(current_params.get('n_jobs', 15) / 15, 2)  # å¹¶å‘è¶Šé«˜ï¼Œå•ä¸ªä»»åŠ¡å¯èƒ½è¶Šæ…¢
            
            timeout_seconds = int(base_timeout * trials_factor * jobs_factor)
            logger.info(f"è®¾ç½®è¶…æ—¶æ—¶é—´: {timeout_seconds} ç§’ ({timeout_seconds/3600:.1f} å°æ—¶)")
            
            result = subprocess.run(cmd, 
                                   capture_output=True, 
                                   text=True, 
                                   timeout=timeout_seconds,
                                   cwd=os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
            
            output = result.stdout + result.stderr
            
            # åœæ­¢è®¡æ—¶å™¨
            stop_timer = True
            timer_thread.join(1)
            
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            end_time = time.time()
            elapsed = end_time - start_time
            
            # æ£€æŸ¥æ‰§è¡Œç»“æœ
            if result.returncode == 0:
                logger.info(f"å‘½ä»¤æ‰§è¡ŒæˆåŠŸ, è€—æ—¶: {elapsed:.2f} ç§’")
                # æå–CAGR
                current_cagr = extract_cagr_from_output(output)
                
                # å¦‚æœå‘ç°æ›´å¥½çš„CAGRï¼Œæ›´æ–°è®°å½•
                if current_cagr > best_record['best_cagr']:
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    
                    # ä¿å­˜æ¨¡å‹æ–‡ä»¶
                    save_model_path = find_latest_model()
                    
                    # ä»æœ€æ–°ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ä¸­è·å–æ­£ç¡®çš„å› å­ä¿¡æ¯ï¼Œè€Œä¸æ˜¯è§£ææ–‡æœ¬è¾“å‡º
                    best_factors = []
                    best_filter_conditions = []
                    
                    if save_model_path and os.path.exists(save_model_path):
                        try:
                            import joblib
                            model_data = joblib.load(save_model_path)
                            
                            # ä»æ¨¡å‹æ–‡ä»¶ä¸­è·å–æ­£ç¡®çš„å› å­ä¿¡æ¯
                            if 'best_rank_factors' in model_data:
                                best_factors = model_data['best_rank_factors']
                                logger.info(f"ä»æ¨¡å‹æ–‡ä»¶ä¸­è·å–åˆ° {len(best_factors)} ä¸ªæ‰“åˆ†å› å­")
                            
                            if 'best_filter_conditions' in model_data:
                                best_filter_conditions = model_data['best_filter_conditions']
                                logger.info(f"ä»æ¨¡å‹æ–‡ä»¶ä¸­è·å–åˆ° {len(best_filter_conditions)} ä¸ªæ’é™¤å› å­æ¡ä»¶")
                                
                        except Exception as e:
                            logger.error(f"ä»æ¨¡å‹æ–‡ä»¶è¯»å–å› å­ä¿¡æ¯å¤±è´¥: {e}")
                    else:
                        logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•è·å–å› å­ä¿¡æ¯: {save_model_path}")
                    
                    if save_model_path:
                        # å¤åˆ¶åˆ°æœ€ä½³æ¨¡å‹ç›®å½•
                        file_ext = os.path.splitext(save_model_path)[1]  # è·å–åŸå§‹æ–‡ä»¶æ‰©å±•å
                        new_model_path = os.path.join(
                            BEST_MODELS_DIR, 
                            f"best_model_cagr{current_cagr:.6f}_seed{current_seed}_{timestamp.replace(':', '-').replace(' ', '_')}{file_ext}"
                        )
                        try:
                            import shutil
                            shutil.copy2(save_model_path, new_model_path)
                            logger.info(f"å·²ä¿å­˜æœ€ä½³æ¨¡å‹: {new_model_path}")
                            
                            # æ›´æ–°å…¨å±€è®°å½•
                            best_record = {
                                "best_cagr": current_cagr,
                                "best_model_path": new_model_path,
                                "timestamp": timestamp,
                                "rank_factors": best_factors,  # é‡å‘½åä¸ºæ›´æ˜ç¡®çš„åç§°
                                "filter_conditions": best_filter_conditions,  # æ·»åŠ æ’é™¤å› å­ä¿¡æ¯
                                "parameters": current_params
                            }
                            save_best_record(best_record)
                        except Exception as e:
                            logger.error(f"ä¿å­˜æœ€ä½³æ¨¡å‹æ—¶å‡ºé”™: {e}")
                    else:
                        logger.warning("æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œæ— æ³•ä¿å­˜æœ€ä½³æ¨¡å‹")
                        
                        # è™½ç„¶æ²¡æœ‰æ¨¡å‹æ–‡ä»¶ï¼Œä½†ä»ç„¶æ›´æ–°CAGRè®°å½•
                        best_record = {
                            "best_cagr": current_cagr,
                            "best_model_path": "",
                            "timestamp": timestamp,
                            "rank_factors": best_factors,  # é‡å‘½åä¸ºæ›´æ˜ç¡®çš„åç§°
                            "filter_conditions": best_filter_conditions,  # æ·»åŠ æ’é™¤å› å­ä¿¡æ¯
                            "parameters": current_params
                        }
                        save_best_record(best_record)
                
                # æ‰“å°æå–åˆ°çš„é‡è¦ç»“æœ
                important_results = extract_important_results(output)
                logger.info("\n==== ä¼˜åŒ–ç»“æœæ‘˜è¦ ====")
                logger.info(important_results)
                    
            else:
                logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥, è€—æ—¶: {elapsed:.2f} ç§’")
                logger.error("\né”™è¯¯è¾“å‡º:")
                logger.error(output.strip())
                
        except subprocess.TimeoutExpired as e:
            # åœæ­¢è®¡æ—¶å™¨
            stop_timer = True
            if timer_thread.is_alive():
                timer_thread.join(1)
                
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            end_time = time.time()
            elapsed = end_time - start_time
            
            logger.error(f"\nå‘½ä»¤æ‰§è¡Œè¶…æ—¶, è€—æ—¶: {elapsed:.2f} ç§’ (è¶…è¿‡ {timeout_seconds} ç§’é™åˆ¶)")
            logger.error(f"è¶…æ—¶å‘½ä»¤: {' '.join(cmd)}")
            logger.error("å»ºè®®: 1) å‡å°‘trialsæ•°é‡ 2) å‡å°‘jobså¹¶å‘æ•° 3) æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¿‡å¤§")
            
        except Exception as e:
            # åœæ­¢è®¡æ—¶å™¨
            stop_timer = True
            if timer_thread.is_alive():
                timer_thread.join(1)
                
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            end_time = time.time()
            elapsed = end_time - start_time
            
            # æ‰“å°è¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯
            import traceback
            logger.error(f"\næ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯, è€—æ—¶: {elapsed:.2f} ç§’")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            logger.error("è¯¦ç»†é”™è¯¯å †æ ˆ:")
            logger.error(traceback.format_exc())
            
            # å¦‚æœæ˜¯ç‰¹å®šçš„å†…å­˜é”™è¯¯ï¼Œç»™å‡ºå»ºè®®
            if "memory" in str(e).lower() or "killed" in str(e).lower():
                logger.error("å¯èƒ½æ˜¯å†…å­˜ä¸è¶³å¯¼è‡´çš„é”™è¯¯ï¼Œå»ºè®®: 1) å‡å°‘jobså¹¶å‘æ•° 2) å‡å°‘æ•°æ®é‡ 3) æ£€æŸ¥ç³»ç»Ÿå†…å­˜")
            elif "permission" in str(e).lower():
                logger.error("å¯èƒ½æ˜¯æƒé™é—®é¢˜ï¼Œå»ºè®®: 1) æ£€æŸ¥æ–‡ä»¶æƒé™ 2) æ£€æŸ¥condaç¯å¢ƒæ¿€æ´» 3) æ£€æŸ¥å·¥ä½œç›®å½•æƒé™")
            elif "module" in str(e).lower() or "import" in str(e).lower():
                logger.error("å¯èƒ½æ˜¯æ¨¡å—å¯¼å…¥é—®é¢˜ï¼Œå»ºè®®: 1) æ£€æŸ¥condaç¯å¢ƒ 2) æ£€æŸ¥åŒ…å®‰è£… 3) æ£€æŸ¥PYTHONPATH")
            elif "connection" in str(e).lower() or "redis" in str(e).lower():
                logger.error("å¯èƒ½æ˜¯Redisè¿æ¥é—®é¢˜ï¼Œå»ºè®®: 1) æ£€æŸ¥RedisæœåŠ¡çŠ¶æ€ 2) æ£€æŸ¥ç½‘ç»œè¿æ¥ 3) å°è¯•é‡å¯RedisæœåŠ¡")

    total_elapsed = time.time() - total_start_time
    logger.info("\n============== ä¼˜åŒ–å®Œæˆ ==============")
    logger.info(f"å†å²æœ€ä½³CAGR: {best_record['best_cagr']:.6f}")
    logger.info(f"æœ€ä½³æ¨¡å‹è·¯å¾„: {best_record['best_model_path']}")
    logger.info(f"å‘ç°æ—¶é—´: {best_record['timestamp']}")
    logger.info(f"æ€»è€—æ—¶: {total_elapsed/60:.2f} åˆ†é’Ÿ")

    # å°è¯•ä»æœ€ä½³è®°å½•ä¸­æå–è¯¦ç»†ä¿¡æ¯
    try:
        if 'model_details' in best_record and best_record['model_details']:
            details = best_record['model_details']

            logger.info("\n============== æœ€ä½³ç­–ç•¥è¯¦æƒ… ==============")

            # æ‰“å°æœ€ä½³æ‰“åˆ†å› å­ç»„åˆ
            if 'rank_factors' in details:
                logger.info("ğŸ“Š æœ€ä½³æ‰“åˆ†å› å­ç»„åˆ:")
                for i, factor in enumerate(details['rank_factors']):
                    direction = "å‡åºæ’åˆ—" if factor['ascending'] else "é™åºæ’åˆ—"
                    logger.info(f"  {i + 1}. {factor['name']} (æƒé‡: {factor['weight']}, {direction})")

            # æ‰“å°æœ€ä½³æ’é™¤å› å­ç»„åˆ
            if 'filter_conditions' in details and details['filter_conditions']:
                logger.info("\nğŸš« æœ€ä½³æ’é™¤å› å­ç»„åˆ:")
                for i, condition in enumerate(details['filter_conditions']):
                    logger.info(f"  {i + 1}. {condition['factor']} {condition['operator']} {condition['value']}")
            else:
                logger.info("\nğŸš« æ’é™¤å› å­ç»„åˆ: æ— ")

            # æ‰“å°ç­–ç•¥å‚æ•°
            if 'strategy_params' in details:
                params = details['strategy_params']
                logger.info(f"\nâš™ï¸ ç­–ç•¥å‚æ•°:")
                logger.info(f"  - å›æµ‹æœŸé—´: {params.get('start_date', 'N/A')} ~ {params.get('end_date', 'N/A')}")
                logger.info(f"  - ä»·æ ¼èŒƒå›´: {params.get('price_min', 'N/A')} ~ {params.get('price_max', 'N/A')}")
                logger.info(f"  - æŒä»“æ•°é‡: {params.get('hold_num', 'N/A')} åª")

    except Exception as e:
        logger.warning(f"æå–æœ€ä½³ç­–ç•¥è¯¦æƒ…æ—¶å‡ºé”™: {e}")
        logger.info("è¯·æŸ¥çœ‹æœ€ä½³æ¨¡å‹æ–‡ä»¶è·å–è¯¦ç»†ä¿¡æ¯")

    logger.info("\n" + "=" * 50)

def extract_important_results(output):
    """ä»ä¼˜åŒ–è¾“å‡ºä¸­æå–é‡è¦ç»“æœ"""
    important_lines = []
    
    # å®šä¹‰å…³é”®å­—æ¨¡å¼
    key_patterns = [
        "æœ€ä½³å¹´åŒ–æ”¶ç›Šç‡", 
        "æœ€ä½³å› å­ç»„åˆ", 
        "å‰5ä¸ªæœ€ä½³ç»„åˆ",
        "Best value",
        "Best trial",
    ]
    
    # è·Ÿè¸ªæ˜¯å¦åœ¨é‡è¦åŒºåŸŸ
    in_important_section = False
    section_lines = []
    
    for line in output.split('\n'):
        # æ£€æŸ¥æ˜¯å¦æ˜¯é‡è¦è¡Œæˆ–åœ¨é‡è¦åŒºåŸŸå†…
        is_important = any(pattern in line for pattern in key_patterns)
        
        if is_important:
            in_important_section = True
            section_lines = [line]  # å¼€å§‹æ–°åŒºåŸŸ
        elif in_important_section:
            if line.strip() == "" and len(section_lines) > 0:
                # ç©ºè¡Œæ ‡å¿—åŒºåŸŸç»“æŸ
                important_lines.extend(section_lines)
                important_lines.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
                in_important_section = False
                section_lines = []
            elif "=" * 20 in line:  # åˆ†éš”çº¿
                section_lines.append(line)
                important_lines.extend(section_lines)
                important_lines.append("")
                in_important_section = False
                section_lines = []
            else:
                section_lines.append(line)
    
    # æ·»åŠ æœ€åä¸€ä¸ªåŒºåŸŸï¼ˆå¦‚æœæœ‰ï¼‰
    if section_lines:
        important_lines.extend(section_lines)
    
    return "\n".join(important_lines)

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='å¯è½¬å€ºå¤šå› å­æŒç»­ä¼˜åŒ–ç¨‹åº')
    parser.add_argument('--iterations', type=int, default=10, help='æŒç»­ä¼˜åŒ–æ¬¡æ•°')
    parser.add_argument('--strategy', type=str, default='multistage', 
                        choices=['domain', 'prescreen', 'multistage', 'filter'],
                        help='ä¼˜åŒ–ç­–ç•¥')
    parser.add_argument('--method', type=str, default='tpe', 
                        choices=['tpe', 'random', 'cmaes'],
                        help='ä¼˜åŒ–æ–¹æ³•')
    parser.add_argument('--n_trials', type=int, default=3000, help='æ¯æ¬¡ä¼˜åŒ–çš„è¿­ä»£æ¬¡æ•°')
    parser.add_argument('--n_factors', type=int, default=3, choices=[3, 4, 5, 6, 7], help='å› å­æ•°é‡')
    parser.add_argument('--start_date', type=str, default='20220729', help='å›æµ‹å¼€å§‹æ—¥æœŸ')
    parser.add_argument('--end_date', type=str, default='20250328', help='å›æµ‹ç»“æŸæ—¥æœŸ')
    parser.add_argument('--price_min', type=int, default=100, help='ä»·æ ¼ä¸‹é™')
    parser.add_argument('--price_max', type=int, default=150, help='ä»·æ ¼ä¸Šé™')
    parser.add_argument('--hold_num', type=int, default=5, help='æŒä»“æ•°é‡')
    parser.add_argument('--n_jobs', type=int, default=15, help='å¹¶è¡Œä»»åŠ¡æ•°')
    parser.add_argument('--seed_start', type=int, default=42, help='èµ·å§‹éšæœºç§å­')
    parser.add_argument('--seed_step', type=int, default=1000, help='ç§å­é€’å¢æ­¥é•¿')
    parser.add_argument('--workspace_id', type=str, default='', help='å·¥ä½œåŒºIDæ ‡è¯†ï¼Œç”¨äºè¿›ç¨‹ç®¡ç†')
    parser.add_argument('--enable_filter_opt', action='store_true', help='å¯ç”¨è¿‡æ»¤å› å­ç»„åˆä¼˜åŒ–')
    
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # è®¾ç½®è¿›ç¨‹æ ‡é¢˜ï¼ŒåŒ…å«å·¥ä½œåŒºID
    try:
        import setproctitle
        if args.workspace_id:
            process_title = f"lude_optimizer_{args.workspace_id}"
            setproctitle.setproctitle(process_title)
            logger.info(f"è¿›ç¨‹æ ‡é¢˜å·²è®¾ç½®ä¸º: {process_title}")
    except ImportError:
        logger.warning("setproctitleæ¨¡å—æœªå®‰è£…ï¼Œæ— æ³•è®¾ç½®è¿›ç¨‹æ ‡é¢˜")
    
    # è¿è¡ŒæŒç»­ä¼˜åŒ–
    run_continuous_optimization(
        iterations=args.iterations,
        strategy=args.strategy,
        method=args.method,
        n_trials=args.n_trials,
        n_factors=args.n_factors,
        start_date=args.start_date,
        end_date=args.end_date,
        price_min=args.price_min,
        price_max=args.price_max,
        hold_num=args.hold_num,
        n_jobs=args.n_jobs,
        seed_start=args.seed_start,
        seed_step=args.seed_step,
        workspace_id=args.workspace_id,
        enable_filter_opt=args.enable_filter_opt
    )

if __name__ == "__main__":
    main()
