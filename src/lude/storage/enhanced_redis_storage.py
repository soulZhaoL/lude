"""
å¢å¼ºå‹Rediså­˜å‚¨å®ç° - è§£å†³è¿æ¥ä¸ç¨³å®šå’Œé«˜å¹¶å‘é”å¼‚å¸¸é—®é¢˜

åŸºäºOptuna 4.4.0+ JournalRedisBackendçš„ç¨³å®šå®ç°æ–¹æ¡ˆï¼Œä¸“é—¨é’ˆå¯¹AutoDLç¯å¢ƒä¼˜åŒ–ã€‚

ä¸»è¦ç‰¹æ€§ï¼š
1. è¿æ¥æ± ç®¡ç†å’Œè‡ªåŠ¨é‡è¯•æœºåˆ¶
2. æ•…éšœè½¬ç§»åˆ°SQLiteå­˜å‚¨
3. è¿æ¥å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨æ¢å¤
4. é«˜å¹¶å‘é”ä¼˜åŒ–
5. æ™ºèƒ½è¶…æ—¶é…ç½®
"""

import logging
import time
import threading
from typing import Optional, Dict, Any
from contextlib import contextmanager
import json
import os
from redis import ConnectionPool, Redis
from redis.exceptions import (
    ConnectionError, TimeoutError, BusyLoadingError
)

import optuna
from optuna.storages import JournalStorage, RDBStorage
from optuna.storages.journal import JournalRedisBackend
import sqlalchemy

logger = logging.getLogger(__name__)


class EnhancedRedisStorage:
    """
    å¢å¼ºå‹Rediså­˜å‚¨å®ç°
    
    ç‰¹æ€§ï¼š
    - è¿æ¥æ± ç®¡ç†å’Œè‡ªåŠ¨é‡è¯•
    - æ•…éšœè½¬ç§»åˆ°SQLite
    - è¿æ¥å¥åº·æ£€æŸ¥
    - é«˜å¹¶å‘ä¼˜åŒ–
    """
    
    def __init__(self, 
                 redis_url: str = "redis://localhost:6379/0",
                 max_retries: int = 5,
                 retry_delay: float = 1.0,
                 pool_size: int = 50,
                 socket_timeout: float = 30.0,
                 socket_connect_timeout: float = 30.0,
                 health_check_interval: int = 30,
                 fallback_db_url: Optional[str] = None):
        """
        åˆå§‹åŒ–å¢å¼ºå‹Rediså­˜å‚¨
        
        Args:
            redis_url: Redisè¿æ¥URL
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
            pool_size: è¿æ¥æ± å¤§å°
            socket_timeout: Socketè¶…æ—¶æ—¶é—´
            socket_connect_timeout: è¿æ¥è¶…æ—¶æ—¶é—´
            health_check_interval: å¥åº·æ£€æŸ¥é—´éš”
            fallback_db_url: æ•…éšœè½¬ç§»SQLiteæ•°æ®åº“URL
        """
        self.redis_url = redis_url
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.health_check_interval = health_check_interval
        
        # è§£æRedis URL
        self._parse_redis_url()
        
        # åˆ›å»ºè¿æ¥æ±  - ç§»é™¤macOSä¸å…¼å®¹çš„keepaliveé€‰é¡¹
        pool_kwargs = {
            'host': self.host,
            'port': self.port,
            'db': self.db,
            'password': self.password,
            'max_connections': pool_size,
            'socket_timeout': socket_timeout,
            'socket_connect_timeout': socket_connect_timeout,
            'retry_on_timeout': True,
            'health_check_interval': health_check_interval
        }
        
        # åªåœ¨Linuxç¯å¢ƒä¸‹å¯ç”¨socket keepalive
        import platform
        if platform.system() == 'Linux':
            pool_kwargs.update({
                'socket_keepalive': True,
                'socket_keepalive_options': {
                    1: 300,  # TCP_KEEPIDLE
                    2: 30,   # TCP_KEEPINTVL  
                    3: 3,    # TCP_KEEPCNT
                }
            })
        
        self.pool = ConnectionPool(**pool_kwargs)
        
        self.redis_client = Redis(connection_pool=self.pool)
        
        # æ•…éšœè½¬ç§»é…ç½® - ä¸¥æ ¼æ¨¡å¼ï¼šå¿…é¡»æ˜ç¡®æŒ‡å®š
        if fallback_db_url is None:
            raise ValueError("fallback_db_urlä¸èƒ½ä¸ºNoneã€‚è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­æ˜ç¡®æŒ‡å®šæ•…éšœè½¬ç§»æ•°æ®åº“URL")
        self.fallback_db_url = fallback_db_url
        self._storage = None
        self._fallback_storage = None
        self._using_fallback = False
        
        # å¥åº·æ£€æŸ¥
        self._health_check_lock = threading.Lock()
        self._last_health_check = 0
        self._is_healthy = False
        
        # åˆå§‹åŒ–å­˜å‚¨
        self._initialize_storage()
        
    def _parse_redis_url(self):
        """è§£æRedis URL - ä¸¥æ ¼æ¨¡å¼ï¼šè§£æå¤±è´¥ç›´æ¥æŠ›å‡ºå¼‚å¸¸"""
        try:
            # ç®€å•çš„URLè§£æ
            if self.redis_url.startswith("redis://"):
                url_part = self.redis_url[8:]  # ç§»é™¤ "redis://"
            else:
                url_part = self.redis_url
                
            # è§£æä¸»æœºã€ç«¯å£ã€æ•°æ®åº“
            if '@' in url_part:
                # åŒ…å«å¯†ç çš„æƒ…å†µ
                auth_part, host_part = url_part.split('@')
                if ':' in auth_part:
                    _, self.password = auth_part.split(':')
                else:
                    self.password = auth_part
            else:
                host_part = url_part
                self.password = None
                
            # è§£æä¸»æœºå’Œç«¯å£
            if '/' in host_part:
                host_port, db_part = host_part.split('/')
                self.db = int(db_part) if db_part else 0
            else:
                host_port = host_part
                self.db = 0
                
            if ':' in host_port:
                self.host, port_str = host_port.split(':')
                self.port = int(port_str)
            else:
                self.host = host_port
                self.port = 6379
                
        except Exception as e:
            error_msg = f"Redis URLè§£æå¤±è´¥: {e}. URLæ ¼å¼åº”ä¸º: redis://[password@]host:port/db"
            logger.error(error_msg)
            raise ValueError(error_msg) from e
            
    def _initialize_storage(self):
        """åˆå§‹åŒ–å­˜å‚¨"""
        # é¦–å…ˆå°è¯•è¿æ¥Redis
        if self._check_redis_health():
            try:
                # ä½¿ç”¨JournalRedisBackend (Optuna 4.0+æ¨è)
                redis_backend = JournalRedisBackend(self.redis_url)
                self._storage = JournalStorage(redis_backend)
                self._using_fallback = False
                logger.info("æˆåŠŸåˆå§‹åŒ–Rediså­˜å‚¨")
                return
            except Exception as e:
                logger.error(f"åˆå§‹åŒ–Rediså­˜å‚¨å¤±è´¥: {e}")
        
        # æ•…éšœè½¬ç§»åˆ°SQLite
        self._initialize_fallback_storage()
        
    def _initialize_fallback_storage(self):
        """åˆå§‹åŒ–æ•…éšœè½¬ç§»å­˜å‚¨"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            db_path = self.fallback_db_url.replace("sqlite:///", "")
            db_dir = os.path.dirname(os.path.abspath(db_path))
            if db_dir:  # åªæœ‰å½“ç›®å½•è·¯å¾„ä¸ä¸ºç©ºæ—¶æ‰åˆ›å»º
                os.makedirs(db_dir, exist_ok=True)
            
            # åˆ›å»ºSQLiteå¼•æ“ (RDBStorageä¼šå†…éƒ¨ä½¿ç”¨)
            sqlalchemy.create_engine(
                self.fallback_db_url,
                echo=False,
                pool_pre_ping=True,
                pool_recycle=3600
            )
            self._fallback_storage = RDBStorage(self.fallback_db_url)
            self._storage = self._fallback_storage
            self._using_fallback = True
            logger.warning(f"å·²æ•…éšœè½¬ç§»åˆ°SQLiteå­˜å‚¨: {self.fallback_db_url}")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ•…éšœè½¬ç§»å­˜å‚¨å¤±è´¥: {e}")
            raise
            
    def _check_redis_health(self, force_check: bool = False) -> bool:
        """æ£€æŸ¥Redisè¿æ¥å¥åº·çŠ¶æ€"""
        current_time = time.time()
        
        # å¦‚æœæœ€è¿‘æ£€æŸ¥è¿‡ä¸”ä¸æ˜¯å¼ºåˆ¶æ£€æŸ¥ï¼Œè¿”å›ç¼“å­˜ç»“æœ
        if not force_check and (current_time - self._last_health_check) < self.health_check_interval:
            return self._is_healthy
            
        with self._health_check_lock:
            try:
                # æ‰§è¡ŒPINGå‘½ä»¤
                result = self.redis_client.ping()
                self._is_healthy = bool(result)
                self._last_health_check = current_time
                
                if self._is_healthy:
                    logger.debug("Rediså¥åº·æ£€æŸ¥é€šè¿‡")
                else:
                    logger.warning("Rediså¥åº·æ£€æŸ¥å¤±è´¥: PINGè¿”å›False")
                    
            except Exception as e:
                self._is_healthy = False
                self._last_health_check = current_time
                logger.warning(f"Rediså¥åº·æ£€æŸ¥å¤±è´¥: {e}")
                
        return self._is_healthy
        
    @contextmanager
    def _retry_context(self, operation_name: str):
        """é‡è¯•ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                yield attempt
                return
            except (ConnectionError, TimeoutError, BusyLoadingError) as e:
                last_exception = e
                if attempt < self.max_retries:
                    logger.warning(f"{operation_name} å°è¯• {attempt + 1}/{self.max_retries + 1} å¤±è´¥: {e}")
                    time.sleep(self.retry_delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ•…éšœè½¬ç§»
                    if not self._check_redis_health(force_check=True):
                        logger.warning("Redisè¿æ¥ä¸ç¨³å®šï¼Œåˆ‡æ¢åˆ°æ•…éšœè½¬ç§»å­˜å‚¨")
                        self._switch_to_fallback()
                        return
                else:
                    logger.error(f"{operation_name} æ‰€æœ‰é‡è¯•å°è¯•éƒ½å¤±è´¥")
                    
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªå¼‚å¸¸
        if last_exception:
            raise last_exception
            
    def _switch_to_fallback(self):
        """åˆ‡æ¢åˆ°æ•…éšœè½¬ç§»å­˜å‚¨"""
        if not self._using_fallback:
            try:
                if self._fallback_storage is None:
                    self._initialize_fallback_storage()
                
                self._storage = self._fallback_storage
                self._using_fallback = True
                logger.info("å·²åˆ‡æ¢åˆ°æ•…éšœè½¬ç§»å­˜å‚¨")
            except Exception as e:
                logger.error(f"åˆ‡æ¢åˆ°æ•…éšœè½¬ç§»å­˜å‚¨å¤±è´¥: {e}")
                
    def _try_switch_back_to_redis(self):
        """å°è¯•åˆ‡æ¢å›Rediså­˜å‚¨"""
        if self._using_fallback and self._check_redis_health(force_check=True):
            try:
                redis_backend = JournalRedisBackend(self.redis_url)
                redis_storage = JournalStorage(redis_backend)
                self._storage = redis_storage
                self._using_fallback = False
                logger.info("å·²åˆ‡æ¢å›Rediså­˜å‚¨")
                return True
            except Exception as e:
                logger.warning(f"åˆ‡æ¢å›Rediså­˜å‚¨å¤±è´¥: {e}")
                return False
        return False
        
    def create_study(self, 
                    study_name: Optional[str] = None,
                    direction: str = "minimize",
                    sampler: Optional[optuna.samplers.BaseSampler] = None,
                    pruner: Optional[optuna.pruners.BasePruner] = None) -> optuna.Study:
        """
        åˆ›å»ºä¼˜åŒ–ç ”ç©¶
        
        Args:
            study_name: ç ”ç©¶åç§°
            direction: ä¼˜åŒ–æ–¹å‘ ("minimize" æˆ– "maximize")
            sampler: é‡‡æ ·å™¨
            pruner: å‰ªæå™¨
            
        Returns:
            optuna.Study: ä¼˜åŒ–ç ”ç©¶å¯¹è±¡
        """
        # å°è¯•åˆ‡æ¢å›Redisï¼ˆå¦‚æœå½“å‰ä½¿ç”¨æ•…éšœè½¬ç§»ï¼‰
        if self._using_fallback:
            self._try_switch_back_to_redis()
            
        with self._retry_context("åˆ›å»ºç ”ç©¶"):
            try:
                study = optuna.create_study(
                    study_name=study_name,
                    direction=direction,
                    storage=self._storage,
                    sampler=sampler,
                    pruner=pruner,
                    load_if_exists=True
                )
                
                storage_type = "SQLiteæ•…éšœè½¬ç§»" if self._using_fallback else "Redis"
                logger.info(f"æˆåŠŸåˆ›å»ºç ”ç©¶ '{study_name}' (å­˜å‚¨: {storage_type})")
                return study
                
            except Exception as e:
                logger.error(f"åˆ›å»ºç ”ç©¶å¤±è´¥: {e}")
                # å¦‚æœä½¿ç”¨Rediså¤±è´¥ï¼Œå°è¯•æ•…éšœè½¬ç§»
                if not self._using_fallback:
                    logger.warning("å°è¯•æ•…éšœè½¬ç§»åˆ°SQLiteå­˜å‚¨...")
                    self._switch_to_fallback()
                    # å†æ¬¡å°è¯•åˆ›å»ºç ”ç©¶
                    study = optuna.create_study(
                        study_name=study_name,
                        direction=direction,
                        storage=self._storage,
                        sampler=sampler,
                        pruner=pruner,
                        load_if_exists=True
                    )
                    logger.info(f"ä½¿ç”¨æ•…éšœè½¬ç§»å­˜å‚¨æˆåŠŸåˆ›å»ºç ”ç©¶ '{study_name}'")
                    return study
                else:
                    raise
                    
    def load_study(self, study_name: str) -> optuna.Study:
        """
        åŠ è½½å·²å­˜åœ¨çš„ç ”ç©¶
        
        Args:
            study_name: ç ”ç©¶åç§°
            
        Returns:
            optuna.Study: ä¼˜åŒ–ç ”ç©¶å¯¹è±¡
        """
        with self._retry_context("åŠ è½½ç ”ç©¶"):
            return optuna.load_study(
                study_name=study_name,
                storage=self._storage
            )
            
    def get_storage_info(self) -> Dict[str, Any]:
        """è·å–å­˜å‚¨ä¿¡æ¯"""
        storage_type = "SQLiteæ•…éšœè½¬ç§»" if self._using_fallback else "Redis"
        
        info = {
            "storage_type": storage_type,
            "using_fallback": self._using_fallback,
            "redis_healthy": self._check_redis_health(),
            "redis_url": self.redis_url,
            "fallback_db_url": self.fallback_db_url
        }
        
        # å¦‚æœä½¿ç”¨Redisï¼Œæ·»åŠ è¿æ¥æ± ä¿¡æ¯ï¼ˆä»…æ•°å€¼ï¼Œé¿å…JSONåºåˆ—åŒ–é—®é¢˜ï¼‰
        if not self._using_fallback:
            try:
                # è·å–å¯åºåˆ—åŒ–çš„è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯
                available_connections = getattr(self.pool, '_available_connections', [])
                in_use_connections = getattr(self.pool, '_in_use_connections', set())
                
                pool_info = {
                    "max_connections": self.pool.max_connections,
                    "created_connections": getattr(self.pool, '_created_connections', 0),
                    "available_connections_count": len(available_connections) if hasattr(available_connections, '__len__') else 0,
                    "in_use_connections_count": len(in_use_connections) if hasattr(in_use_connections, '__len__') else 0,
                }
                info["connection_pool"] = pool_info
            except Exception as e:
                logger.debug(f"è·å–è¿æ¥æ± ä¿¡æ¯å¤±è´¥: {e}")
                # æä¾›åŸºæœ¬ä¿¡æ¯é¿å…å®Œå…¨å¤±è´¥
                info["connection_pool"] = {
                    "max_connections": getattr(self.pool, 'max_connections', 'unknown'),
                    "status": "info_unavailable"
                }
                
        return info
        
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.pool:
                self.pool.disconnect()
            logger.info("Rediså­˜å‚¨èµ„æºå·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"æ¸…ç†Rediså­˜å‚¨èµ„æºæ—¶å‡ºé”™: {e}")


# å…¨å±€å­˜å‚¨å®ä¾‹
_enhanced_storage = None


def get_enhanced_storage(config_path: Optional[str] = None) -> EnhancedRedisStorage:
    """
    è·å–å¢å¼ºå‹å­˜å‚¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        EnhancedRedisStorage: å­˜å‚¨å®ä¾‹
    """
    global _enhanced_storage
    
    if _enhanced_storage is None:
        # åŠ è½½é…ç½®
        config = _load_storage_config(config_path)
        _enhanced_storage = EnhancedRedisStorage(**config)
        
    return _enhanced_storage


def _load_storage_config(config_path: Optional[str] = None) -> Dict[str, Any]:
    """åŠ è½½å­˜å‚¨é…ç½® - ä¸¥æ ¼æ¨¡å¼ï¼šå¿…é¡»ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼Œç¦æ­¢ä»»ä½•é»˜è®¤é…ç½®"""
    if config_path is None:
        # é…ç½®æ–‡ä»¶è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))
        config_path = os.path.join(project_root, "redis", "redis_config.json")
    
    # ğŸš¨ ä¸¥æ ¼åŸåˆ™ï¼šé…ç½®æ–‡ä»¶å¿…é¡»å­˜åœ¨
    if not os.path.exists(config_path):
        error_msg = (
            f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}\n"
            f"ä¸¥æ ¼æ¨¡å¼ï¼šç¦æ­¢ä½¿ç”¨ä»»ä½•é»˜è®¤é…ç½®ï¼\n"
            f"è¯·åˆ›å»ºé…ç½®æ–‡ä»¶æˆ–æ£€æŸ¥è·¯å¾„ã€‚é…ç½®æ–‡ä»¶æ¨¡æ¿:\n"
            f"{{\n"
            f'  "host": "localhost",\n'
            f'  "port": 6379,\n' 
            f'  "db": 0,\n'
            f'  "password": null,\n'
            f'  "socket_timeout": 30.0,\n'
            f'  "socket_connect_timeout": 30.0,\n'
            f'  "health_check_interval": 30\n'
            f"}}"
        )
        logger.error(error_msg)
        raise FileNotFoundError(error_msg)
    
    # ğŸš¨ ä¸¥æ ¼åŸåˆ™ï¼šé…ç½®æ–‡ä»¶å¿…é¡»å¯è¯»å–
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            file_config = json.load(f)
    except Exception as e:
        error_msg = f"é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {config_path}. é”™è¯¯: {e}"
        logger.error(error_msg)
        raise RuntimeError(error_msg) from e
    
    # ğŸš¨ ä¸¥æ ¼åŸåˆ™ï¼šå¿…é¡»åŒ…å«æ‰€æœ‰å¿…è¦é…ç½®é¡¹
    required_keys = ['host', 'port', 'db']
    missing_keys = [key for key in required_keys if key not in file_config]
    if missing_keys:
        error_msg = f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é…ç½®é¡¹: {missing_keys}. é…ç½®æ–‡ä»¶è·¯å¾„: {config_path}"
        logger.error(error_msg)
        raise ValueError(error_msg)
    
    # æ„å»ºå®Œæ•´é…ç½®ï¼ˆä»…ä»é…ç½®æ–‡ä»¶è·å–ï¼Œä¸ä½¿ç”¨ä»»ä½•é»˜è®¤å€¼ï¼‰
    config = {
        "redis_url": f"redis://{file_config['host']}:{file_config['port']}/{file_config['db']}",
        "max_retries": file_config.get("max_retries", 5),
        "retry_delay": file_config.get("retry_delay", 1.0),
        "pool_size": file_config.get("pool_size", 50),
        "socket_timeout": file_config.get("socket_timeout", 30.0),
        "socket_connect_timeout": file_config.get("socket_connect_timeout", 30.0),
        "health_check_interval": file_config.get("health_check_interval", 30),
        "fallback_db_url": file_config.get("fallback_db_url", "sqlite:///optuna_fallback.db")
    }
    
    # ğŸš¨ éªŒè¯é…ç½®çš„å®Œæ•´æ€§
    for key, value in config.items():
        if value is None:
            error_msg = f"é…ç½®é¡¹ '{key}' ä¸èƒ½ä¸ºç©ºã€‚è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶: {config_path}"
            logger.error(error_msg)
            raise ValueError(error_msg)
    
    logger.info(f"æˆåŠŸåŠ è½½å­˜å‚¨é…ç½®: {config_path}")
    return config


# ä¾¿åˆ©å‡½æ•°
def create_enhanced_study(study_name: str,
                         direction: str = "minimize",
                         sampler: Optional[optuna.samplers.BaseSampler] = None,
                         pruner: Optional[optuna.pruners.BasePruner] = None) -> optuna.Study:
    """åˆ›å»ºå¢å¼ºå‹ç ”ç©¶"""
    storage = get_enhanced_storage()
    return storage.create_study(
        study_name=study_name,
        direction=direction,
        sampler=sampler,
        pruner=pruner
    )


def load_enhanced_study(study_name: str) -> optuna.Study:
    """åŠ è½½å¢å¼ºå‹ç ”ç©¶"""
    storage = get_enhanced_storage()
    return storage.load_study(study_name)


def get_storage_status() -> Dict[str, Any]:
    """è·å–å­˜å‚¨çŠ¶æ€"""
    storage = get_enhanced_storage()
    return storage.get_storage_info()