import os
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional
from scipy import stats
from lude.config.paths import DATA_DIR

class FactorDistributionAnalyzer:
    """
    å› å­æ•°å€¼åˆ†å¸ƒåˆ†æå·¥å…·ç±»
    
    ç”¨äºåˆ†æå¯è½¬å€ºå› å­çš„æ•°å€¼åˆ†å¸ƒç‰¹å¾ï¼ŒåŒ…æ‹¬ç»Ÿè®¡æŒ‡æ ‡ã€åˆ†å¸ƒå›¾å½¢ç­‰
    """
    
    def __init__(self, data_path: Optional[str] = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨cb_data.pq
        """
        if data_path is None:
            self.data_path = os.path.join(DATA_DIR, 'cb_data.pq')
        else:
            self.data_path = data_path
        
        self.df = None
        self._load_data()
    
    def _load_data(self):
        """åŠ è½½æ•°æ®"""
        try:
            self.df = pd.read_parquet(self.data_path)
            print(f"æ•°æ®åŠ è½½æˆåŠŸ: {self.df.shape[0]}è¡Œ, {self.df.shape[1]}åˆ—")
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def get_basic_stats(self, factor_name: str) -> Dict[str, Any]:
        """
        è·å–å› å­çš„åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            factor_name: å› å­åç§°
            
        Returns:
            åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        if factor_name not in self.df.columns:
            raise ValueError(f"å› å­ '{factor_name}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        series = self.df[factor_name].dropna()
        
        if len(series) == 0:
            return {"error": "è¯¥å› å­æ— æœ‰æ•ˆæ•°æ®"}
        
        stats_dict = {
            "æ•°æ®æ€»æ•°": len(self.df[factor_name]),
            "æœ‰æ•ˆæ•°æ®": len(series),
            "ç¼ºå¤±æ•°æ®": len(self.df[factor_name]) - len(series),
            "ç¼ºå¤±ç‡": (len(self.df[factor_name]) - len(series)) / len(self.df[factor_name]) * 100,
            "å‡å€¼": series.mean(),
            "ä¸­ä½æ•°": series.median(),
            "æ ‡å‡†å·®": series.std(),
            "æ–¹å·®": series.var(),
            "ååº¦": series.skew(),
            "å³°åº¦": series.kurtosis(),
            "æœ€å°å€¼": series.min(),
            "æœ€å¤§å€¼": series.max(),
            "æå·®": series.max() - series.min(),
            "25%åˆ†ä½æ•°": series.quantile(0.25),
            "75%åˆ†ä½æ•°": series.quantile(0.75),
            "å››åˆ†ä½è·": series.quantile(0.75) - series.quantile(0.25),
            "å˜å¼‚ç³»æ•°": series.std() / series.mean() if series.mean() != 0 else np.inf
        }
        
        # æ·»åŠ æ­£æ€æ€§æ£€éªŒ
        if len(series) >= 3:
            try:
                shapiro_stat, shapiro_p = stats.shapiro(series.sample(min(5000, len(series))))
                stats_dict["Shapiroæ­£æ€æ€§æ£€éªŒç»Ÿè®¡é‡"] = shapiro_stat
                stats_dict["Shapiroæ­£æ€æ€§æ£€éªŒpå€¼"] = shapiro_p
                stats_dict["æ˜¯å¦æ­£æ€åˆ†å¸ƒ"] = shapiro_p > 0.05
            except:
                stats_dict["æ­£æ€æ€§æ£€éªŒ"] = "æ— æ³•æ‰§è¡Œ"
        
        return stats_dict
    
    def print_basic_stats(self, factor_name: str):
        """
        æ‰“å°å› å­çš„åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            factor_name: å› å­åç§°
        """
        stats = self.get_basic_stats(factor_name)
        
        if "error" in stats:
            print(f"é”™è¯¯: {stats['error']}")
            return
        
        print(f"\n{'='*60}")
        print(f"å› å­ '{factor_name}' çš„åˆ†å¸ƒç»Ÿè®¡ä¿¡æ¯")
        print(f"{'='*60}")
        
        print(f"\nã€æ•°æ®æ¦‚å†µã€‘")
        print(f"  æ•°æ®æ€»æ•°: {stats['æ•°æ®æ€»æ•°']:,}")
        print(f"  æœ‰æ•ˆæ•°æ®: {stats['æœ‰æ•ˆæ•°æ®']:,}")
        print(f"  ç¼ºå¤±æ•°æ®: {stats['ç¼ºå¤±æ•°æ®']:,}")
        print(f"  ç¼ºå¤±ç‡: {stats['ç¼ºå¤±ç‡']:.2f}%")
        
        print(f"\nã€ä¸­å¿ƒè¶‹åŠ¿ã€‘")
        print(f"  å‡å€¼: {stats['å‡å€¼']:.6f}")
        print(f"  ä¸­ä½æ•°: {stats['ä¸­ä½æ•°']:.6f}")
        
        print(f"\nã€ç¦»æ•£ç¨‹åº¦ã€‘")
        print(f"  æ ‡å‡†å·®: {stats['æ ‡å‡†å·®']:.6f}")
        print(f"  æ–¹å·®: {stats['æ–¹å·®']:.6f}")
        print(f"  å˜å¼‚ç³»æ•°: {stats['å˜å¼‚ç³»æ•°']:.6f}")
        print(f"  æå·®: {stats['æå·®']:.6f}")
        print(f"  å››åˆ†ä½è·: {stats['å››åˆ†ä½è·']:.6f}")
        
        print(f"\nã€åˆ†å¸ƒå½¢çŠ¶ã€‘")
        print(f"  ååº¦: {stats['ååº¦']:.6f}")
        print(f"  å³°åº¦: {stats['å³°åº¦']:.6f}")
        
        print(f"\nã€æå€¼ä¿¡æ¯ã€‘")
        print(f"  æœ€å°å€¼: {stats['æœ€å°å€¼']:.6f}")
        print(f"  æœ€å¤§å€¼: {stats['æœ€å¤§å€¼']:.6f}")
        print(f"  25%åˆ†ä½æ•°: {stats['25%åˆ†ä½æ•°']:.6f}")
        print(f"  75%åˆ†ä½æ•°: {stats['75%åˆ†ä½æ•°']:.6f}")
        
        if "Shapiroæ­£æ€æ€§æ£€éªŒpå€¼" in stats:
            print(f"\nã€æ­£æ€æ€§æ£€éªŒã€‘")
            print(f"  Shapiroç»Ÿè®¡é‡: {stats['Shapiroæ­£æ€æ€§æ£€éªŒç»Ÿè®¡é‡']:.6f}")
            print(f"  på€¼: {stats['Shapiroæ­£æ€æ€§æ£€éªŒpå€¼']:.6f}")
            print(f"  æ˜¯å¦æ­£æ€åˆ†å¸ƒ: {'æ˜¯' if stats['æ˜¯å¦æ­£æ€åˆ†å¸ƒ'] else 'å¦'}")
    
    def get_distribution_values(self, factor_name: str, sample_mode: str = 'percentile') -> Dict[str, Any]:
        """
        è·å–å› å­çš„åˆ†å¸ƒæ•°å€¼
        
        Args:
            factor_name: å› å­åç§°
            sample_mode: é‡‡æ ·æ¨¡å¼ï¼Œ'percentile' ä¸ºåˆ†ä½æ•°æ¨¡å¼ï¼Œ'head_tail' ä¸ºå¤´å°¾æ¨¡å¼
            
        Returns:
            åŒ…å«åˆ†å¸ƒæ•°å€¼çš„å­—å…¸
        """
        if factor_name not in self.df.columns:
            raise ValueError(f"å› å­ '{factor_name}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        series = self.df[factor_name].dropna()
        
        if len(series) == 0:
            return {"error": "è¯¥å› å­æ— æœ‰æ•ˆæ•°æ®"}
        
        if sample_mode == 'percentile':
            # æŒ‰åˆ†ä½æ•°é‡‡æ ·
            percentiles = [0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100]
            result = {}
            
            for p in percentiles:
                result[f"{p}%åˆ†ä½æ•°"] = series.quantile(p/100)
            
            return result
            
        elif sample_mode == 'head_tail':
            # å¤´éƒ¨/å°¾éƒ¨ + åˆ†ä½æ•°æ¨¡å¼
            sorted_series = series.sort_values()
            result = {}
            
            # å¤´éƒ¨æ•°æ® (å‰10ä¸ª)
            head_count = min(10, len(sorted_series))
            for i in range(head_count):
                result[f"å¤´éƒ¨ç¬¬{i+1}å°"] = sorted_series.iloc[i]
            
            # å°¾éƒ¨æ•°æ® (å10ä¸ª)
            tail_count = min(10, len(sorted_series))
            for i in range(tail_count):
                result[f"å°¾éƒ¨ç¬¬{i+1}å¤§"] = sorted_series.iloc[-(i+1)]
            
            # åˆ†ä½æ•°
            percentiles = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95]
            for p in percentiles:
                result[f"{p}%åˆ†ä½æ•°"] = series.quantile(p/100)
            
            return result
        
        else:
            raise ValueError("sample_modeå‚æ•°å¿…é¡»æ˜¯ 'percentile' æˆ– 'head_tail'")
    
    def print_distribution_values(self, factor_name: str, sample_mode: str = 'percentile'):
        """
        æ‰“å°å› å­çš„åˆ†å¸ƒæ•°å€¼
        
        Args:
            factor_name: å› å­åç§°
            sample_mode: é‡‡æ ·æ¨¡å¼
        """
        values = self.get_distribution_values(factor_name, sample_mode)
        
        if "error" in values:
            print(f"é”™è¯¯: {values['error']}")
            return
        
        print(f"\n{'='*60}")
        print(f"å› å­ '{factor_name}' çš„åˆ†å¸ƒæ•°å€¼")
        print(f"{'='*60}")
        
        if sample_mode == 'head_tail':
            # å…ˆæ‰“å°å¤´éƒ¨æ•°æ®
            print(f"\nã€å¤´éƒ¨æ•°æ® (æœ€å°å€¼)ã€‘")
            for key, value in values.items():
                if "å¤´éƒ¨" in key:
                    print(f"  {key}: {value:.6f}")
            
            # å†æ‰“å°å°¾éƒ¨æ•°æ®
            print(f"\nã€å°¾éƒ¨æ•°æ® (æœ€å¤§å€¼)ã€‘")
            for key, value in values.items():
                if "å°¾éƒ¨" in key:
                    print(f"  {key}: {value:.6f}")
        
        # æ‰“å°åˆ†ä½æ•°
        print(f"\nã€åˆ†ä½æ•°åˆ†å¸ƒã€‘")
        for key, value in values.items():
            if "åˆ†ä½æ•°" in key:
                print(f"  {key}: {value:.6f}")
    
    def get_percentile_analysis(self, factor_name: str, percentiles: List[float] = None) -> Dict[str, float]:
        """
        è·å–å› å­çš„åˆ†ä½æ•°åˆ†æ
        
        Args:
            factor_name: å› å­åç§°
            percentiles: åˆ†ä½æ•°åˆ—è¡¨ï¼Œé»˜è®¤ä¸º[1, 5, 10, 25, 50, 75, 90, 95, 99]
            
        Returns:
            åˆ†ä½æ•°å­—å…¸
        """
        if percentiles is None:
            percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
        
        if factor_name not in self.df.columns:
            raise ValueError(f"å› å­ '{factor_name}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        series = self.df[factor_name].dropna()
        
        if len(series) == 0:
            return {"error": "è¯¥å› å­æ— æœ‰æ•ˆæ•°æ®"}
        
        percentile_dict = {}
        for p in percentiles:
            percentile_dict[f"{p}%åˆ†ä½æ•°"] = series.quantile(p/100)
        
        return percentile_dict
    
    def print_percentile_analysis(self, factor_name: str, percentiles: List[float] = None):
        """
        æ‰“å°å› å­çš„åˆ†ä½æ•°åˆ†æ
        
        Args:
            factor_name: å› å­åç§°
            percentiles: åˆ†ä½æ•°åˆ—è¡¨
        """
        percentile_dict = self.get_percentile_analysis(factor_name, percentiles)
        
        if "error" in percentile_dict:
            print(f"é”™è¯¯: {percentile_dict['error']}")
            return
        
        print(f"\nã€åˆ†ä½æ•°åˆ†æã€‘")
        for key, value in percentile_dict.items():
            print(f"  {key}: {value:.6f}")
    
    def detect_outliers(self, factor_name: str, method: str = 'iqr') -> Dict[str, Any]:
        """
        æ£€æµ‹å¼‚å¸¸å€¼
        
        Args:
            factor_name: å› å­åç§°
            method: æ£€æµ‹æ–¹æ³•ï¼Œ'iqr' æˆ– 'zscore'
            
        Returns:
            å¼‚å¸¸å€¼åˆ†æç»“æœ
        """
        if factor_name not in self.df.columns:
            raise ValueError(f"å› å­ '{factor_name}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        series = self.df[factor_name].dropna()
        
        if len(series) == 0:
            return {"error": "è¯¥å› å­æ— æœ‰æ•ˆæ•°æ®"}
        
        if method == 'iqr':
            Q1 = series.quantile(0.25)
            Q3 = series.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = series[(series < lower_bound) | (series > upper_bound)]
            
            return {
                "æ–¹æ³•": "IQRæ–¹æ³•",
                "ä¸‹ç•Œ": lower_bound,
                "ä¸Šç•Œ": upper_bound,
                "å¼‚å¸¸å€¼æ•°é‡": len(outliers),
                "å¼‚å¸¸å€¼æ¯”ä¾‹": len(outliers) / len(series) * 100,
                "å¼‚å¸¸å€¼": outliers.tolist() if len(outliers) <= 20 else "å¼‚å¸¸å€¼è¿‡å¤šï¼Œä»…æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"
            }
        
        elif method == 'zscore':
            z_scores = np.abs(stats.zscore(series))
            threshold = 3
            outliers = series[z_scores > threshold]
            
            return {
                "æ–¹æ³•": "Z-Scoreæ–¹æ³•",
                "é˜ˆå€¼": threshold,
                "å¼‚å¸¸å€¼æ•°é‡": len(outliers),
                "å¼‚å¸¸å€¼æ¯”ä¾‹": len(outliers) / len(series) * 100,
                "å¼‚å¸¸å€¼": outliers.tolist() if len(outliers) <= 20 else "å¼‚å¸¸å€¼è¿‡å¤šï¼Œä»…æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"
            }
        
        else:
            raise ValueError("methodå‚æ•°å¿…é¡»æ˜¯ 'iqr' æˆ– 'zscore'")
    
    def print_outlier_analysis(self, factor_name: str, method: str = 'iqr'):
        """
        æ‰“å°å¼‚å¸¸å€¼åˆ†æ
        
        Args:
            factor_name: å› å­åç§°
            method: æ£€æµ‹æ–¹æ³•
        """
        outlier_info = self.detect_outliers(factor_name, method)
        
        if "error" in outlier_info:
            print(f"é”™è¯¯: {outlier_info['error']}")
            return
        
        print(f"\nã€å¼‚å¸¸å€¼æ£€æµ‹ - {outlier_info['æ–¹æ³•']}ã€‘")
        
        if method == 'iqr':
            print(f"  ä¸‹ç•Œ: {outlier_info['ä¸‹ç•Œ']:.6f}")
            print(f"  ä¸Šç•Œ: {outlier_info['ä¸Šç•Œ']:.6f}")
        else:
            print(f"  Z-Scoreé˜ˆå€¼: {outlier_info['é˜ˆå€¼']}")
        
        print(f"  å¼‚å¸¸å€¼æ•°é‡: {outlier_info['å¼‚å¸¸å€¼æ•°é‡']}")
        print(f"  å¼‚å¸¸å€¼æ¯”ä¾‹: {outlier_info['å¼‚å¸¸å€¼æ¯”ä¾‹']:.2f}%")
        
        if isinstance(outlier_info['å¼‚å¸¸å€¼'], list) and len(outlier_info['å¼‚å¸¸å€¼']) > 0:
            print(f"  å¼‚å¸¸å€¼æ ·æœ¬: {outlier_info['å¼‚å¸¸å€¼'][:10]}")  # åªæ˜¾ç¤ºå‰10ä¸ª
    
    def comprehensive_analysis(self, factor_name: str, include_head_tail: bool = False):
        """
        ç»¼åˆåˆ†ææŸä¸ªå› å­
        
        Args:
            factor_name: å› å­åç§°
            include_head_tail: æ˜¯å¦åŒ…å«å¤´å°¾æ•°æ®
        """
        print(f"\nğŸ” å¼€å§‹å¯¹å› å­ '{factor_name}' è¿›è¡Œç»¼åˆåˆ†æ...")
        
        # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        self.print_basic_stats(factor_name)
        
        # åˆ†å¸ƒæ•°å€¼åˆ†æ
        if include_head_tail:
            self.print_distribution_values(factor_name, 'head_tail')
        else:
            self.print_distribution_values(factor_name, 'percentile')
        
        # å¼‚å¸¸å€¼æ£€æµ‹ (IQRæ–¹æ³•)
        self.print_outlier_analysis(factor_name, 'iqr')
        
        print(f"\nâœ… å› å­ '{factor_name}' åˆ†æå®Œæˆ!")
    
    def batch_analysis(self, factor_names: List[str], include_head_tail: bool = False):
        """
        æ‰¹é‡åˆ†æå¤šä¸ªå› å­
        
        Args:
            factor_names: å› å­åç§°åˆ—è¡¨
            include_head_tail: æ˜¯å¦åŒ…å«å¤´å°¾æ•°æ®
        """
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ {len(factor_names)} ä¸ªå› å­...")
        
        for i, factor_name in enumerate(factor_names, 1):
            print(f"\n{'='*80}")
            print(f"æ­£åœ¨åˆ†æç¬¬ {i}/{len(factor_names)} ä¸ªå› å­: {factor_name}")
            print(f"{'='*80}")
            
            try:
                self.comprehensive_analysis(factor_name, include_head_tail=include_head_tail)
            except Exception as e:
                print(f"âŒ åˆ†æå› å­ '{factor_name}' æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"\nğŸ‰ æ‰¹é‡åˆ†æå®Œæˆ!")


if __name__ == "__main__":
    # åˆ›å»ºåˆ†æå™¨å®ä¾‹
    analyzer = FactorDistributionAnalyzer()
    
    # è®¾ç½®è¦åˆ†æçš„å› å­åç§°
    # å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹è¿™é‡Œçš„å› å­åç§°
    target_factors = [
        'theory_bias',          
        # 'amount',          # é‡‘é¢ç›¸å…³
        # 'conv_prem',       # è½¬æ¢æº¢ä»·ç‡
        # 'bias_5',          # 5æ—¥åå·®
        # 'price_ratio',   # ä»·æ ¼æ¯”ç‡ (å¦‚æœå­˜åœ¨çš„è¯)
        # 'volume_ratio',  # æˆäº¤é‡æ¯”ç‡ (å¦‚æœå­˜åœ¨çš„è¯)
    ]
    
    print("ğŸ“Š å› å­æ•°å€¼åˆ†å¸ƒåˆ†æå·¥å…·")
    print("=" * 50)
    
    # å•ä¸ªå› å­è¯¦ç»†åˆ†æç¤ºä¾‹
    if target_factors:
        print(f"\nğŸ¯ å¯¹å› å­ '{target_factors[0]}' è¿›è¡Œåˆ†ä½æ•°åˆ†æ:")
        analyzer.print_distribution_values(target_factors[0], 'percentile')
        
        # print(f"\nğŸ¯ å¯¹å› å­ '{target_factors[0]}' è¿›è¡Œå¤´å°¾+åˆ†ä½æ•°åˆ†æ:")
        # analyzer.print_distribution_values(target_factors[0], 'head_tail')
    
    # æ‰¹é‡åˆ†æç¤ºä¾‹ (æ³¨é‡Šæ‰ï¼Œéœ€è¦æ—¶å¯å–æ¶ˆæ³¨é‡Š)
    # print(f"\nğŸ“ˆ æ‰¹é‡åˆ†ææ‰€æœ‰ç›®æ ‡å› å­:")
    # analyzer.batch_analysis(target_factors)
    
    # å¯ç”¨å› å­åˆ—è¡¨ (æ–¹ä¾¿å‚è€ƒ)
    # print(f"\nğŸ“‹ æ•°æ®ä¸­çš„æ‰€æœ‰å› å­åˆ—è¡¨ (å…±{len(analyzer.df.columns)}ä¸ª):")
    # for i, col in enumerate(analyzer.df.columns):
    #     if i % 5 == 0:
    #         print()
    #     print(f"{col:20}", end="")
    print("\n")
    
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. ä¿®æ”¹ target_factors åˆ—è¡¨æ¥åˆ†æä¸åŒçš„å› å­")
    print("2. ä½¿ç”¨ analyzer.print_distribution_values('å› å­å', 'percentile') æŸ¥çœ‹åˆ†ä½æ•°")
    print("3. ä½¿ç”¨ analyzer.print_distribution_values('å› å­å', 'head_tail') æŸ¥çœ‹å¤´å°¾+åˆ†ä½æ•°")
    print("4. å–æ¶ˆæ³¨é‡Šæ‰¹é‡åˆ†æä»£ç æ¥åˆ†æå¤šä¸ªå› å­")