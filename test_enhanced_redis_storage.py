#!/usr/bin/env python3
"""
å¢å¼ºå‹Rediså­˜å‚¨ç¨³å®šæ€§æµ‹è¯•è„šæœ¬

æµ‹è¯•åŠŸèƒ½ï¼š
1. Redisè¿æ¥ç¨³å®šæ€§
2. é«˜å¹¶å‘åœºæ™¯ä¸‹çš„æ€§èƒ½
3. æ•…éšœè½¬ç§»æœºåˆ¶
4. è¿æ¥æ± ç®¡ç†
5. è‡ªåŠ¨é‡è¯•æœºåˆ¶

ä½¿ç”¨æ–¹æ³•ï¼š
source ~/miniconda3/etc/profile.d/conda.sh && conda activate lude && python test_enhanced_redis_storage.py
"""

import os
import sys
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Any
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(current_dir, "src")
sys.path.insert(0, src_dir)

from lude.storage.enhanced_redis_storage import (
    get_enhanced_storage,
    create_enhanced_study,
    get_storage_status
)


def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('test_enhanced_redis.log')
        ]
    )
    return logging.getLogger(__name__)


def simple_objective(trial):
    """ç®€å•çš„ä¼˜åŒ–ç›®æ ‡å‡½æ•°"""
    x = trial.suggest_float("x", -10, 10)
    y = trial.suggest_float("y", -10, 10)
    return x**2 + y**2


def complex_objective(trial):
    """å¤æ‚çš„ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œæ¨¡æ‹Ÿå®é™…åœºæ™¯"""
    # æ¨¡æ‹Ÿå› å­é€‰æ‹©å’Œæƒé‡ä¼˜åŒ–
    n_factors = trial.suggest_int("n_factors", 2, 5)
    total_score = 0
    
    for i in range(n_factors):
        weight = trial.suggest_float(f"factor_{i}_weight", 0.1, 2.0)
        direction = trial.suggest_categorical(f"factor_{i}_direction", [True, False])
        
        # æ¨¡æ‹Ÿå› å­è®¡ç®—
        factor_value = trial.suggest_float(f"factor_{i}_value", -1, 1)
        score = weight * factor_value * (1 if direction else -1)
        total_score += score
        
    # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—å»¶è¿Ÿ
    time.sleep(0.1)
    
    return abs(total_score)


def test_basic_connection():
    """æµ‹è¯•åŸºæœ¬è¿æ¥åŠŸèƒ½"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ§ª æµ‹è¯•åŸºæœ¬è¿æ¥åŠŸèƒ½...")
    
    try:
        storage = get_enhanced_storage()
        status = storage.get_storage_info()
        
        logger.info(f"å­˜å‚¨ç±»å‹: {status['storage_type']}")
        logger.info(f"Rediså¥åº·çŠ¶æ€: {status['redis_healthy']}")
        logger.info(f"ä½¿ç”¨æ•…éšœè½¬ç§»: {status['using_fallback']}")
        
        if not status['using_fallback'] and 'connection_pool' in status:
            pool_info = status['connection_pool']
            logger.info(f"è¿æ¥æ± çŠ¶æ€: {pool_info}")
            
        return True
        
    except Exception as e:
        logger.error(f"åŸºæœ¬è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_single_study():
    """æµ‹è¯•å•ä¸ªç ”ç©¶åˆ›å»ºå’Œä¼˜åŒ–"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ§ª æµ‹è¯•å•ä¸ªç ”ç©¶åˆ›å»ºå’Œä¼˜åŒ–...")
    
    try:
        study_name = f"test_single_study_{int(time.time())}"
        study = create_enhanced_study(
            study_name=study_name,
            direction="minimize"
        )
        
        # è¿è¡Œå°‘é‡è¯•éªŒ
        study.optimize(simple_objective, n_trials=10)
        
        # æ£€æŸ¥ç»“æœ
        best_trial = study.best_trial
        logger.info(f"æœ€ä½³è¯•éªŒå€¼: {best_trial.value}")
        logger.info(f"æœ€ä½³å‚æ•°: {best_trial.params}")
        
        return True
        
    except Exception as e:
        logger.error(f"å•ä¸ªç ”ç©¶æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_concurrent_studies(n_studies: int = 5, n_trials_per_study: int = 20):
    """æµ‹è¯•å¹¶å‘ç ”ç©¶"""
    logger = logging.getLogger(__name__)
    logger.info(f"ğŸ§ª æµ‹è¯•å¹¶å‘ç ”ç©¶ ({n_studies}ä¸ªç ”ç©¶ï¼Œæ¯ä¸ª{n_trials_per_study}æ¬¡è¯•éªŒ)...")
    
    def run_single_study(study_id: int) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªç ”ç©¶"""
        try:
            study_name = f"test_concurrent_study_{study_id}_{int(time.time())}"
            study = create_enhanced_study(
                study_name=study_name,
                direction="minimize"
            )
            
            start_time = time.time()
            study.optimize(complex_objective, n_trials=n_trials_per_study)
            end_time = time.time()
            
            best_trial = study.best_trial
            return {
                "study_id": study_id,
                "study_name": study_name,
                "success": True,
                "best_value": best_trial.value,
                "n_trials": len(study.trials),
                "duration": end_time - start_time,
                "error": None
            }
            
        except Exception as e:
            return {
                "study_id": study_id,
                "study_name": f"test_concurrent_study_{study_id}",
                "success": False,
                "best_value": None,
                "n_trials": 0,
                "duration": 0,
                "error": str(e)
            }
    
    # å¹¶å‘æ‰§è¡Œç ”ç©¶
    results = []
    with ThreadPoolExecutor(max_workers=n_studies) as executor:
        future_to_study = {
            executor.submit(run_single_study, i): i 
            for i in range(n_studies)
        }
        
        for future in as_completed(future_to_study):
            study_id = future_to_study[future]
            try:
                result = future.result()
                results.append(result)
                
                if result["success"]:
                    logger.info(f"ç ”ç©¶ {study_id} å®Œæˆ: æœ€ä½³å€¼={result['best_value']:.4f}, "
                              f"è¯•éªŒæ•°={result['n_trials']}, è€—æ—¶={result['duration']:.2f}s")
                else:
                    logger.error(f"ç ”ç©¶ {study_id} å¤±è´¥: {result['error']}")
                    
            except Exception as e:
                logger.error(f"ç ”ç©¶ {study_id} æ‰§è¡Œå¼‚å¸¸: {e}")
                results.append({
                    "study_id": study_id,
                    "success": False,
                    "error": str(e)
                })
    
    # ç»Ÿè®¡ç»“æœ
    successful_studies = [r for r in results if r["success"]]
    failed_studies = [r for r in results if not r["success"]]
    
    logger.info(f"âœ… æˆåŠŸçš„ç ”ç©¶: {len(successful_studies)}/{n_studies}")
    logger.info(f"âŒ å¤±è´¥çš„ç ”ç©¶: {len(failed_studies)}/{n_studies}")
    
    if successful_studies:
        avg_duration = sum(r["duration"] for r in successful_studies) / len(successful_studies)
        avg_trials = sum(r["n_trials"] for r in successful_studies) / len(successful_studies)
        logger.info(f"å¹³å‡è€—æ—¶: {avg_duration:.2f}s")
        logger.info(f"å¹³å‡è¯•éªŒæ•°: {avg_trials:.1f}")
    
    if failed_studies:
        logger.warning("å¤±è´¥çš„ç ”ç©¶é”™è¯¯ä¿¡æ¯:")
        for result in failed_studies:
            logger.warning(f"  ç ”ç©¶ {result['study_id']}: {result['error']}")
    
    return len(successful_studies) == n_studies


def test_failover_mechanism():
    """æµ‹è¯•æ•…éšœè½¬ç§»æœºåˆ¶"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ§ª æµ‹è¯•æ•…éšœè½¬ç§»æœºåˆ¶...")
    
    try:
        # è·å–å½“å‰å­˜å‚¨çŠ¶æ€
        storage = get_enhanced_storage()
        initial_status = storage.get_storage_info()
        logger.info(f"åˆå§‹å­˜å‚¨ç±»å‹: {initial_status['storage_type']}")
        
        # åˆ›å»ºä¸€ä¸ªç ”ç©¶
        study_name = f"test_failover_{int(time.time())}"
        study = create_enhanced_study(
            study_name=study_name,
            direction="minimize"
        )
        
        # è¿è¡Œä¸€äº›è¯•éªŒ
        study.optimize(simple_objective, n_trials=5)
        logger.info(f"æ•…éšœè½¬ç§»å‰å®Œæˆäº† {len(study.trials)} æ¬¡è¯•éªŒ")
        
        # å¦‚æœå½“å‰ä½¿ç”¨Redisï¼Œå°è¯•è§¦å‘æ•…éšœè½¬ç§»
        if not initial_status['using_fallback']:
            logger.info("å½“å‰ä½¿ç”¨Rediså­˜å‚¨ï¼Œæ•…éšœè½¬ç§»æœºåˆ¶æ­£å¸¸å¾…å‘½")
        else:
            logger.info("å½“å‰å·²åœ¨ä½¿ç”¨æ•…éšœè½¬ç§»å­˜å‚¨")
        
        # ç»§ç»­è¿è¡Œæ›´å¤šè¯•éªŒ
        study.optimize(simple_objective, n_trials=5)
        logger.info(f"æ€»å…±å®Œæˆäº† {len(study.trials)} æ¬¡è¯•éªŒ")
        
        # æ£€æŸ¥æœ€ç»ˆçŠ¶æ€
        final_status = storage.get_storage_info()
        logger.info(f"æœ€ç»ˆå­˜å‚¨ç±»å‹: {final_status['storage_type']}")
        
        return True
        
    except Exception as e:
        logger.error(f"æ•…éšœè½¬ç§»æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_connection_recovery():
    """æµ‹è¯•è¿æ¥æ¢å¤æœºåˆ¶"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ§ª æµ‹è¯•è¿æ¥æ¢å¤æœºåˆ¶...")
    
    try:
        storage = get_enhanced_storage()
        
        # æ‰§è¡Œå¤šæ¬¡å¥åº·æ£€æŸ¥ï¼Œæ¨¡æ‹Ÿè¿æ¥ä¸ç¨³å®šçš„æƒ…å†µ
        for i in range(10):
            is_healthy = storage._check_redis_health(force_check=True)
            logger.info(f"å¥åº·æ£€æŸ¥ {i+1}/10: {'é€šè¿‡' if is_healthy else 'å¤±è´¥'}")
            time.sleep(1)
        
        # å°è¯•åˆ›å»ºç ”ç©¶ï¼Œæµ‹è¯•è¿æ¥æ¢å¤
        study_name = f"test_recovery_{int(time.time())}"
        study = create_enhanced_study(
            study_name=study_name,
            direction="minimize"
        )
        
        study.optimize(simple_objective, n_trials=3)
        logger.info("è¿æ¥æ¢å¤æµ‹è¯•å®Œæˆ")
        
        return True
        
    except Exception as e:
        logger.error(f"è¿æ¥æ¢å¤æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_high_concurrency_simulation(n_workers: int = 10, n_trials_per_worker: int = 10):
    """æ¨¡æ‹Ÿé«˜å¹¶å‘åœºæ™¯"""
    logger = logging.getLogger(__name__)
    logger.info(f"ğŸ§ª æ¨¡æ‹Ÿé«˜å¹¶å‘åœºæ™¯ ({n_workers}ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œæ¯ä¸ª{n_trials_per_worker}æ¬¡è¯•éªŒ)...")
    
    def worker_function(worker_id: int) -> Dict[str, Any]:
        """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
        try:
            study_name = f"test_high_concurrency_worker_{worker_id}_{int(time.time())}"
            study = create_enhanced_study(
                study_name=study_name,
                direction="minimize"
            )
            
            start_time = time.time()
            study.optimize(simple_objective, n_trials=n_trials_per_worker)
            end_time = time.time()
            
            return {
                "worker_id": worker_id,
                "success": True,
                "n_trials": len(study.trials),
                "duration": end_time - start_time,
                "best_value": study.best_trial.value,
                "error": None
            }
            
        except Exception as e:
            return {
                "worker_id": worker_id,
                "success": False,
                "n_trials": 0,
                "duration": 0,
                "best_value": None,
                "error": str(e)
            }
    
    # å¹¶å‘æ‰§è¡Œ
    results = []
    with ThreadPoolExecutor(max_workers=n_workers) as executor:
        future_to_worker = {
            executor.submit(worker_function, i): i 
            for i in range(n_workers)
        }
        
        for future in as_completed(future_to_worker):
            worker_id = future_to_worker[future]
            try:
                result = future.result()
                results.append(result)
                
                if result["success"]:
                    logger.info(f"å·¥ä½œçº¿ç¨‹ {worker_id} å®Œæˆ: {result['n_trials']}æ¬¡è¯•éªŒ, "
                              f"è€—æ—¶{result['duration']:.2f}s, æœ€ä½³å€¼{result['best_value']:.4f}")
                else:
                    logger.error(f"å·¥ä½œçº¿ç¨‹ {worker_id} å¤±è´¥: {result['error']}")
                    
            except Exception as e:
                logger.error(f"å·¥ä½œçº¿ç¨‹ {worker_id} å¼‚å¸¸: {e}")
    
    # ç»Ÿè®¡ç»“æœ
    successful_workers = [r for r in results if r["success"]]
    failed_workers = [r for r in results if not r["success"]]
    
    logger.info(f"âœ… æˆåŠŸçš„å·¥ä½œçº¿ç¨‹: {len(successful_workers)}/{n_workers}")
    logger.info(f"âŒ å¤±è´¥çš„å·¥ä½œçº¿ç¨‹: {len(failed_workers)}/{n_workers}")
    
    if successful_workers:
        total_trials = sum(r["n_trials"] for r in successful_workers)
        total_duration = max(r["duration"] for r in successful_workers)
        avg_duration = sum(r["duration"] for r in successful_workers) / len(successful_workers)
        
        logger.info(f"æ€»è¯•éªŒæ¬¡æ•°: {total_trials}")
        logger.info(f"æ€»è€—æ—¶: {total_duration:.2f}s")
        logger.info(f"å¹³å‡æ¯çº¿ç¨‹è€—æ—¶: {avg_duration:.2f}s")
        logger.info(f"è¯•éªŒååé‡: {total_trials/total_duration:.2f} trials/s")
    
    return len(failed_workers) == 0


def run_comprehensive_test():
    """è¿è¡Œå…¨é¢æµ‹è¯•"""
    logger = setup_logging()
    logger.info("ğŸš€ å¼€å§‹å¢å¼ºå‹Rediså­˜å‚¨å…¨é¢æµ‹è¯•...")
    
    test_results = []
    
    # æµ‹è¯•1: åŸºæœ¬è¿æ¥
    logger.info("\n" + "="*60)
    test_results.append(("åŸºæœ¬è¿æ¥æµ‹è¯•", test_basic_connection()))
    
    # æµ‹è¯•2: å•ä¸ªç ”ç©¶
    logger.info("\n" + "="*60)
    test_results.append(("å•ä¸ªç ”ç©¶æµ‹è¯•", test_single_study()))
    
    # æµ‹è¯•3: å¹¶å‘ç ”ç©¶
    logger.info("\n" + "="*60)
    test_results.append(("å¹¶å‘ç ”ç©¶æµ‹è¯•", test_concurrent_studies(n_studies=30, n_trials_per_study=15)))
    
    # æµ‹è¯•4: æ•…éšœè½¬ç§»
    logger.info("\n" + "="*60)
    test_results.append(("æ•…éšœè½¬ç§»æµ‹è¯•", test_failover_mechanism()))
    
    # æµ‹è¯•5: è¿æ¥æ¢å¤
    logger.info("\n" + "="*60)
    test_results.append(("è¿æ¥æ¢å¤æµ‹è¯•", test_connection_recovery()))
    
    # æµ‹è¯•6: é«˜å¹¶å‘æ¨¡æ‹Ÿ
    logger.info("\n" + "="*60)
    test_results.append(("é«˜å¹¶å‘æµ‹è¯•", test_high_concurrency_simulation(n_workers=15, n_trials_per_worker=300)))
    
    # æ±‡æ€»ç»“æœ
    logger.info("\n" + "="*60)
    logger.info("ğŸ æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed_tests = 0
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
        if result:
            passed_tests += 1
    
    logger.info(f"\næ€»æµ‹è¯•é€šè¿‡ç‡: {passed_tests}/{len(test_results)} ({passed_tests/len(test_results)*100:.1f}%)")
    
    # æœ€ç»ˆå­˜å‚¨çŠ¶æ€
    try:
        final_status = get_storage_status()
        logger.info(f"\næœ€ç»ˆå­˜å‚¨çŠ¶æ€: {json.dumps(final_status, indent=2, ensure_ascii=False)}")
    except Exception as e:
        logger.warning(f"è·å–æœ€ç»ˆå­˜å‚¨çŠ¶æ€å¤±è´¥: {e}")
    
    if passed_tests == len(test_results):
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¢å¼ºå‹Rediså­˜å‚¨å·¥ä½œæ­£å¸¸ã€‚")
        return True
    else:
        logger.warning(f"âš ï¸  æœ‰ {len(test_results) - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return False


if __name__ == "__main__":
    success = run_comprehensive_test()
    sys.exit(0 if success else 1)